# File: /home/jobbe/Desktop/Projects/emlak-web/utils/system_check.py
"""Utility to check system dependencies for video generation."""

import subprocess
import shutil
import platform
import os
import streamlit as st

def check_ffmpeg():
    """Check if FFmpeg is installed and working."""
    try:
        ffmpeg_path = shutil.which('ffmpeg')
        if ffmpeg_path:
            result = subprocess.run(['ffmpeg', '-version'], 
                                  stdout=subprocess.PIPE, 
                                  stderr=subprocess.PIPE,
                                  text=True)
            return True, ffmpeg_path, result.stdout.split('\n')[0]
        else:
            return False, None, "FFmpeg not found in PATH"
    except Exception as e:
        return False, None, str(e)

def check_opencv():
    """Check OpenCV version and capabilities."""
    import cv2
    version = cv2.__version__
    
    # Check if OpenCV was built with video support
    has_video = "Video I/O" in cv2.getBuildInformation()
    
    # Check available video codecs
    codecs = []
    for codec in ['XVID', 'MJPG', 'X264', 'AVC1', 'H264']:
        try:
            if cv2.VideoWriter_fourcc(*codec) != -1:
                codecs.append(codec)
        except:
            pass
    
    return version, has_video, codecs

def check_system_resources():
    """Check system resources."""
    try:
        import psutil
        
        # Memory info
        memory = psutil.virtual_memory()
        free_memory_gb = memory.available / (1024**3)
        
        # CPU info
        cpu_count = os.cpu_count()
        cpu_usage = psutil.cpu_percent(interval=1)
        
        # Disk info
        disk = psutil.disk_usage('/')
        free_disk_gb = disk.free / (1024**3)
        
        return {
            "free_memory_gb": free_memory_gb,
            "cpu_count": cpu_count,
            "cpu_usage": cpu_usage,
            "free_disk_gb": free_disk_gb
        }
    except ImportError:
        return {
            "error": "psutil module not installed",
            "cpu_count": os.cpu_count()
        }

def run_dependency_checks():
    """Run all dependency checks and return results."""
    results = {}
    
    # System info
    results["system"] = {
        "platform": platform.system(),
        "platform_version": platform.version(),
        "python_version": platform.python_version()
    }
    
    # FFmpeg
    ffmpeg_ok, ffmpeg_path, ffmpeg_version = check_ffmpeg()
    results["ffmpeg"] = {
        "available": ffmpeg_ok,
        "path": ffmpeg_path,
        "version": ffmpeg_version
    }
    
    # OpenCV
    try:
        cv_version, has_video, codecs = check_opencv()
        results["opencv"] = {
            "version": cv_version,
            "has_video": has_video,
            "available_codecs": codecs
        }
    except Exception as e:
        results["opencv"] = {
            "error": str(e)
        }
    
    # System resources
    results["resources"] = check_system_resources()
    
    return results

def display_system_info():
    """Display system information in Streamlit."""
    with st.expander("ğŸ–¥ï¸ Sistem Bilgileri"):
        try:
            results = run_dependency_checks()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Sistem")
                st.write(f"**Platform:** {results['system']['platform']} {results['system']['platform_version']}")
                st.write(f"**Python:** {results['system']['python_version']}")
                
                if 'resources' in results and 'error' not in results['resources']:
                    st.subheader("Kaynaklar")
                    if "free_memory_gb" in results['resources']:
                        st.write(f"**BoÅŸ Bellek:** {results['resources']['free_memory_gb']:.1f} GB")
                    st.write(f"**CPU Ã‡ekirdek:** {results['resources']['cpu_count']}")
                    if "cpu_usage" in results['resources']:
                        st.write(f"**CPU KullanÄ±mÄ±:** {results['resources']['cpu_usage']}%")
                    if "free_disk_gb" in results['resources']:
                        st.write(f"**BoÅŸ Disk:** {results['resources']['free_disk_gb']:.1f} GB")
            
            with col2:
                st.subheader("FFmpeg")
                if results['ffmpeg']['available']:
                    st.success("âœ… FFmpeg kurulu")
                    st.write(f"**Versiyon:** {results['ffmpeg']['version']}")
                else:
                    st.error("âŒ FFmpeg kurulu deÄŸil")
                    st.write("FFmpeg video oluÅŸturma iÃ§in gereklidir.")
                
                st.subheader("OpenCV")
                if 'error' not in results['opencv']:
                    st.write(f"**Versiyon:** {results['opencv']['version']}")
                    if results['opencv']['has_video']:
                        st.success("âœ… Video desteÄŸi mevcut")
                    else:
                        st.warning("âš ï¸ OpenCV video desteÄŸi sÄ±nÄ±rlÄ±")
                    
                    st.write(f"**Kodekler:** {', '.join(results['opencv']['available_codecs'])}")
                else:
                    st.error(f"âŒ OpenCV hatasÄ±: {results['opencv']['error']}")
        
        except Exception as e:
            st.error(f"Sistem bilgileri alÄ±namadÄ±: {str(e)}")
            
        st.info("Video oluÅŸturma iÅŸlemi sÄ±rasÄ±nda sorun yaÅŸÄ±yorsanÄ±z, FFmpeg ve OpenCV'nin dÃ¼zgÃ¼n kurulduÄŸundan emin olun.")

# Add this to your app setup or settings page
if __name__ == "__main__":
    display_system_info()
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/utils/background_tasks.py
"""Background task management utilities."""

import time
import threading
import traceback
import gc
import os
import tempfile
import numpy as np
import streamlit as st
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, TimeoutError
from PIL import Image

# These imports might be causing circular dependencies - let's fix them
from modules.video.video_generation import generate_video

class BackgroundTaskManager:
    """Manages background tasks and their statuses."""
    
    def __init__(self):
        """Initialize the background task manager"""
        self.tasks = {}
        # Reduce thread pool size to prevent memory issues
        self.executor = ThreadPoolExecutor(max_workers=1)
        self._lock = threading.Lock()
        
    def start_task(self, task_function, task_args=None, task_name="task", timeout=3600):
        """
        Start a background task with timeout
        
        Args:
            task_function: The function to execute in background
            task_args: Arguments to pass to the function
            task_name: Name of the task
            timeout: Timeout for the task in seconds
            
        Returns:
            Task ID
        """
        if task_args is None:
            task_args = ()
            
        # Generate a task ID
        task_id = f"{task_name}_{int(time.time())}"
        
        # Create a task status dictionary
        with self._lock:
            self.tasks[task_id] = {
                "status": "starting",
                "start_time": datetime.now(),
                "progress": 0,
                "result": None,
                "error": None,
                "error_details": None,
                "message": "Ä°ÅŸlem baÅŸlatÄ±lÄ±yor...",
                "timeout": timeout
            }
        
        # Submit task with timeout handling
        future = self.executor.submit(self._run_task, task_function, task_args, task_id)
        
        # Add timeout handling
        def timeout_handler():
            time.sleep(timeout)
            if not future.done():
                with self._lock:
                    if task_id in self.tasks and self.tasks[task_id]["status"] == "running":
                        self.tasks[task_id]["status"] = "failed"
                        self.tasks[task_id]["error"] = "Ä°ÅŸlem zaman aÅŸÄ±mÄ±na uÄŸradÄ±"
                        self.tasks[task_id]["message"] = "Zaman aÅŸÄ±mÄ± hatasÄ±!"
                future.cancel()
        
        threading.Thread(target=timeout_handler, daemon=True).start()
        return task_id
        
    def _run_task(self, task_function, task_args, task_id):
        """
        Execute the task and update its status
        
        Args:
            task_function: Function to execute
            task_args: Arguments for the function
            task_id: Task ID
        """
        try:
            # Force garbage collection before starting
            gc.collect()
            
            # Update status to running
            with self._lock:
                self.tasks[task_id]["status"] = "running"
                self.tasks[task_id]["message"] = "Ä°ÅŸlem Ã§alÄ±ÅŸÄ±yor..."
            
            # Create a progress callback
            def progress_callback(progress_percentage, message=None):
                with self._lock:
                    if task_id in self.tasks:
                        # Ensure progress is between 0-100
                        self.tasks[task_id]["progress"] = min(100, max(0, progress_percentage * 100))
                        if message:
                            self.tasks[task_id]["message"] = message
                            print(f"Progress update: {message} ({progress_percentage:.1%})")
            
            # Run the task with timeout handling
            max_duration = 1800  # 30 minutes max
            task_args_with_callback = task_args + (progress_callback,)
                
            # Execute task with progress callback
            result = task_function(*task_args_with_callback)
            
            # Task completed successfully
            with self._lock:
                if task_id in self.tasks:
                    self.tasks[task_id]["status"] = "completed"
                    self.tasks[task_id]["result"] = result
                    self.tasks[task_id]["progress"] = 100
                    self.tasks[task_id]["message"] = "Ä°ÅŸlem baÅŸarÄ±yla tamamlandÄ±."
            
            # Force garbage collection to free memory
            gc.collect()
            
        except Exception as e:
            # Task failed
            error_details = traceback.format_exc()
            print(f"Task {task_id} failed: {str(e)}")
            print(error_details)
            
            with self._lock:
                if task_id in self.tasks:
                    self.tasks[task_id]["status"] = "failed"
                    self.tasks[task_id]["error"] = str(e)
                    self.tasks[task_id]["error_details"] = error_details
                    self.tasks[task_id]["message"] = f"Hata: {str(e)}"
            
            # Force garbage collection on error too
            gc.collect()
    
    def get_task_status(self, task_id):
        """
        Get the current status of a task
        
        Args:
            task_id: The task ID
            
        Returns:
            Task status dictionary or None if task doesn't exist
        """
        with self._lock:
            return self.tasks.get(task_id)
    
    def cancel_task(self, task_id):
        """
        Cancel a running task
        
        Args:
            task_id: The task ID
            
        Returns:
            True if task was canceled, False otherwise
        """
        with self._lock:
            if task_id in self.tasks and self.tasks[task_id]["status"] == "running":
                # We can't actually stop the thread, but we can mark it as canceled
                self.tasks[task_id]["status"] = "canceled"
                return True
        return False
    
    def cleanup_completed_tasks(self, max_age_seconds=3600):
        """
        Remove old completed tasks from memory
        
        Args:
            max_age_seconds: Maximum age of completed tasks to keep
        """
        current_time = datetime.now()
        with self._lock:
            tasks_to_remove = []
            
            for task_id, task_data in self.tasks.items():
                if task_data["status"] in ["completed", "failed", "canceled"]:
                    task_age = current_time - task_data["start_time"]
                    if task_age.total_seconds() > max_age_seconds:
                        tasks_to_remove.append(task_id)
            
            for task_id in tasks_to_remove:
                del self.tasks[task_id]


def generate_video_in_background(images, audio_path, transition_type, fps=30, quality="normal", temp_dir=None, final_path=None, progress_callback=None):
    """Background task wrapper for video generation"""
    try:
        # Create default paths if not provided
        if temp_dir is None:
            temp_dir = os.path.join(os.path.dirname(__file__), '..', 'temp')
        if final_path is None:
            storage_dir = os.path.join(os.path.dirname(__file__), '..', 'storage')
            timestamp = time.strftime("%Y%m%d-%H%M%S")
            final_path = os.path.join(storage_dir, f'emlak_video_{timestamp}.mp4')

        # Ensure directories exist
        os.makedirs(os.path.dirname(temp_dir), exist_ok=True)
        os.makedirs(os.path.dirname(final_path), exist_ok=True)

        return generate_video(
            images, 
            audio_path, 
            transition_type, 
            fps, 
            quality,
            temp_dir,
            final_path,
            progress_callback
        )
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"Video generation error: {str(e)}\n{error_details}")
        raise
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/utils/utils.py
"""General utility functions for the application."""

from math import radians, sin, cos, sqrt, atan2
import shutil
import os
import streamlit as st  # Eksik import eklendi

def calculate_distance(lat1, lng1, lat2, lng2):
    """
    Calculate the distance between two coordinates in meters.
    
    Args:
        lat1, lng1: Latitude and longitude of first point
        lat2, lng2: Latitude and longitude of second point
        
    Returns:
        Distance in meters
    """
    # Approximate radius of earth in km
    R = 6373.0
    
    lat1, lng1, lat2, lng2 = map(radians, [lat1, lng1, lat2, lng2])
    
    dlon = lng2 - lng1
    dlat = lat2 - lat1
    
    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    
    distance = R * c
    
    return round(distance * 1000)  # Convert to meters

def cleanup_temp_files(filepath):
    """Clean up temporary files and directories."""
    try:
        if filepath and os.path.exists(filepath):
            temp_dir = os.path.dirname(filepath)
            shutil.rmtree(temp_dir, ignore_errors=True)
    except Exception as e:
        st.warning(f"Cleanup warning: {str(e)}")
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/utils/state_manager.py
"""
GeliÅŸmiÅŸ durum yÃ¶netimi (state management) iÃ§in araÃ§lar.
"""

import streamlit as st
import json
import os
import pickle
from datetime import datetime
from typing import Dict, Any, Optional, Union, List

class StateManager:
    """Emlak video uygulamasÄ± iÃ§in geliÅŸmiÅŸ durum yÃ¶netimi sÄ±nÄ±fÄ±"""
    
    def __init__(self, storage_dir: str = None):
        """
        StateManager baÅŸlatÄ±cÄ±
        
        Args:
            storage_dir: Durum verilerinin saklanacaÄŸÄ± dizin
        """
        if storage_dir is None:
            storage_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "storage")
        self.storage_dir = storage_dir
        os.makedirs(storage_dir, exist_ok=True)
        
        # Mevcut durum dosyalarÄ±nÄ± yÃ¼kle
        self._project_list = self._load_project_list()
        
    def save_state(self, project_name: str, overwrite: bool = False) -> bool:
        """
        Mevcut uygulama durumunu kaydeder
        
        Args:
            project_name: Proje adÄ±
            overwrite: True ise, mevcut projenin Ã¼zerine yazar
            
        Returns:
            Ä°ÅŸlemin baÅŸarÄ±lÄ± olup olmadÄ±ÄŸÄ±
        """
        # AynÄ± isimde proje var mÄ± kontrol et
        if not overwrite and project_name in self._project_list:
            return False
        
        # Saklanacak session_state anahtarlarÄ±nÄ± belirle
        keys_to_save = [
            'property_location',
            'property_text',
            'audio_path',
            'maps_images',
            'user_images',
            'bordered_property_image',
            'video_quality',
            'transition_type',
            'fps',
            'enhance_colors',
            'color_boost'
        ]
        
        # Sadece mevcut anahtarlarÄ± sakla
        state_data = {}
        for key in keys_to_save:
            if key in st.session_state:
                # PIL.Image ve dosya nesneleri gibi karmaÅŸÄ±k nesneleri iÅŸle
                if key == 'maps_images' or key == 'user_images':
                    # GÃ¶rÃ¼ntÃ¼leri sakla
                    images_dir = os.path.join(self.storage_dir, project_name, 'images', key)
                    os.makedirs(images_dir, exist_ok=True)
                    saved_paths = []
                    
                    for idx, img in enumerate(st.session_state[key]):
                        img_path = os.path.join(images_dir, f"image_{idx}.png")
                        img.save(img_path)
                        saved_paths.append(img_path)
                    
                    state_data[key] = saved_paths
                elif key == 'audio_path':
                    # Ses dosyasÄ±nÄ± sakla
                    if os.path.exists(st.session_state[key]):
                        audio_dir = os.path.join(self.storage_dir, project_name, 'audio')
                        os.makedirs(audio_dir, exist_ok=True)
                        audio_path = os.path.join(audio_dir, 'audio.mp3')
                        
                        with open(st.session_state[key], 'rb') as src_file:
                            with open(audio_path, 'wb') as dst_file:
                                dst_file.write(src_file.read())
                                
                        state_data[key] = audio_path
                else:
                    state_data[key] = st.session_state[key]
        
        # Proje meta verilerini ekle
        state_data['_metadata'] = {
            'saved_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'version': '1.0'
        }
        
        # Projeyi kaydet
        try:
            project_dir = os.path.join(self.storage_dir, project_name)
            os.makedirs(project_dir, exist_ok=True)
            
            # Ana durum dosyasÄ±nÄ± kaydet
            state_path = os.path.join(project_dir, 'state.json')
            with open(state_path, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, ensure_ascii=False, default=str)
            
            # Proje listesini gÃ¼ncelle
            if project_name not in self._project_list:
                self._project_list.append(project_name)
                self._save_project_list()
                
            return True
        except Exception as e:
            st.error(f"Proje kaydedilemedi: {str(e)}")
            return False
            
    def load_state(self, project_name: str) -> bool:
        """
        KaydedilmiÅŸ bir projeyi yÃ¼kler
        
        Args:
            project_name: YÃ¼klenecek proje adÄ±
            
        Returns:
            Ä°ÅŸlemin baÅŸarÄ±lÄ± olup olmadÄ±ÄŸÄ±
        """
        try:
            project_dir = os.path.join(self.storage_dir, project_name)
            state_path = os.path.join(project_dir, 'state.json')
            
            if not os.path.exists(state_path):
                return False
                
            # JSON durum verilerini yÃ¼kle
            with open(state_path, 'r', encoding='utf-8') as f:
                state_data = json.load(f)
            
            # GÃ¶rÃ¼ntÃ¼ ve ses dosyalarÄ±nÄ± iÅŸle
            for key, value in state_data.items():
                if key == 'maps_images' or key == 'user_images':
                    # GÃ¶rÃ¼ntÃ¼leri PIL nesneleri olarak yÃ¼kle
                    images = []
                    for img_path in value:
                        if os.path.exists(img_path):
                            from PIL import Image
                            img = Image.open(img_path)
                            images.append(img)
                    
                    if images:
                        st.session_state[key] = images
                elif key != '_metadata':
                    # DiÄŸer deÄŸerleri doÄŸrudan aktar
                    st.session_state[key] = value
            
            return True
        except Exception as e:
            st.error(f"Proje yÃ¼klenemedi: {str(e)}")
            return False
            
    def get_project_list(self) -> List[str]:
        """Mevcut projelerin listesini dÃ¶ndÃ¼rÃ¼r"""
        return self._project_list
        
    def delete_project(self, project_name: str) -> bool:
        """
        Bir projeyi siler
        
        Args:
            project_name: Silinecek proje adÄ±
            
        Returns:
            Ä°ÅŸlemin baÅŸarÄ±lÄ± olup olmadÄ±ÄŸÄ±
        """
        try:
            project_dir = os.path.join(self.storage_dir, project_name)
            
            if os.path.exists(project_dir):
                import shutil
                shutil.rmtree(project_dir)
            
            # Proje listesini gÃ¼ncelle
            if project_name in self._project_list:
                self._project_list.remove(project_name)
                self._save_project_list()
                
            return True
        except Exception as e:
            st.error(f"Proje silinemedi: {str(e)}")
            return False
            
    def _load_project_list(self) -> List[str]:
        """Proje listesini dosyadan yÃ¼kler"""
        list_path = os.path.join(self.storage_dir, 'project_list.json')
        
        if os.path.exists(list_path):
            try:
                with open(list_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return []
        else:
            return []
            
    def _save_project_list(self) -> None:
        """Proje listesini dosyaya kaydeder"""
        list_path = os.path.join(self.storage_dir, 'project_list.json')
        
        with open(list_path, 'w', encoding='utf-8') as f:
            json.dump(self._project_list, f, ensure_ascii=False)

    def get_project_data(self):
        """
        Mevcut durumdan proje verilerini alÄ±r
        
        Returns:
            Proje verileri sÃ¶zlÃ¼ÄŸÃ¼
        """
        # Saklanacak session_state anahtarlarÄ±nÄ± belirle
        keys_to_save = [
            'property_location',
            'property_text',
            'audio_path',
            'maps_images',
            'user_images',
            'bordered_property_image',
            'video_quality',
            'transition_type',
            'fps',
            'enhance_colors',
            'color_boost'
        ]
        
        # Sadece mevcut anahtarlarÄ± al
        project_data = {}
        for key in keys_to_save:
            if key in st.session_state:
                project_data[key] = st.session_state[key]
        
        return project_data
        
    def set_project_data(self, project_data):
        """
        Proje verilerini mevcut duruma ayarlar
        
        Args:
            project_data: Ayarlanacak proje verileri sÃ¶zlÃ¼ÄŸÃ¼
        """
        for key, value in project_data.items():
            st.session_state[key] = value
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/utils/__init__.py
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/utils/cache_utils.py
"""Custom cache utilities for storing and retrieving data."""

import os
import pickle
import hashlib
import time
import shutil
import functools
import streamlit as st
from pathlib import Path

# Create cache directory in user's home directory
CACHE_DIR = Path.home() / ".emlak_web_cache"
CACHE_DIR.mkdir(exist_ok=True)

# In-memory cache dictionary
_memory_cache = {}

def _get_cache_key(func_name, args, kwargs):
    """Generate a unique cache key based on function name and arguments."""
    key_parts = [func_name]
    
    # Add stringified args and kwargs
    for arg in args:
        key_parts.append(str(arg))
    
    for k, v in sorted(kwargs.items()):
        key_parts.append(f"{k}={v}")
    
    # Create a hash from the key parts
    key_string = "_".join(key_parts)
    return hashlib.md5(key_string.encode()).hexdigest()

def cached_data(ttl=3600):
    """
    Decorator to cache function results in memory and on disk.
    
    Args:
        ttl: Time to live for cache entries in seconds (default: 1 hour)
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # Generate a unique key for this function call
            cache_key = _get_cache_key(func.__name__, args, kwargs)
            
            # Check memory cache first
            if cache_key in _memory_cache:
                value, timestamp = _memory_cache[cache_key]
                if time.time() - timestamp < ttl:
                    return value
            
            # Check disk cache if not in memory or expired
            cache_file = CACHE_DIR / f"{cache_key}.pkl"
            if cache_file.exists():
                try:
                    with open(cache_file, 'rb') as f:
                        value, timestamp = pickle.load(f)
                        if time.time() - timestamp < ttl:
                            # Store in memory for faster access next time
                            _memory_cache[cache_key] = (value, timestamp)
                            return value
                except (pickle.PickleError, EOFError):
                    # If any error loading from disk, just regenerate
                    pass
            
            # Cache miss or expired - call the function
            value = func(*args, **kwargs)
            
            # Store result in both memory and disk cache
            current_time = time.time()
            _memory_cache[cache_key] = (value, current_time)
            
            try:
                with open(cache_file, 'wb') as f:
                    pickle.dump((value, current_time), f)
            except Exception:
                # If disk cache fails, we still have the memory cache
                pass
                
            return value
        return wrapper
    return decorator

def clear_cache():
    """Clear the in-memory cache."""
    _memory_cache.clear()
    st.success("Memory cache cleared!")

def clear_disk_cache():
    """Clear the disk cache."""
    try:
        for file in CACHE_DIR.glob("*.pkl"):
            file.unlink()
        st.success("Disk cache cleared!")
    except Exception as e:
        st.error(f"Error clearing disk cache: {str(e)}")
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/utils/wizard_utils.py
"""Utilities for the step-by-step wizard interface."""

import streamlit as st
import time
from typing import List, Callable, Dict, Any

class WizardStep:
    def __init__(self, title: str, description: str, render_func: Callable):
        """
        Initialize a step in the wizard.
        
        Args:
            title: Step title
            description: Step description
            render_func: Function that renders the step content
        """
        self.title = title
        self.description = description
        self.render_func = render_func
        self.is_complete = False
        self.validation_error = None

class Wizard:
    def __init__(self, name: str, steps: List[WizardStep]):
        """
        Create a wizard with multiple steps.
        
        Args:
            name: Wizard name
            steps: List of WizardStep objects
        """
        self.name = name
        self.steps = steps
        
        # Initialize wizard state in session if not exists
        if f"wizard_{name}_current_step" not in st.session_state:
            st.session_state[f"wizard_{name}_current_step"] = 0
        
        if f"wizard_{name}_data" not in st.session_state:
            st.session_state[f"wizard_{name}_data"] = {}
    
    @property
    def current_step_index(self) -> int:
        """Get the current step index."""
        return st.session_state.get(f"wizard_{self.name}_current_step", 0)
    
    @current_step_index.setter
    def current_step_index(self, value: int):
        """Set the current step index."""
        st.session_state[f"wizard_{self.name}_current_step"] = value
    
    @property
    def current_step(self) -> WizardStep:
        """Get the current step."""
        return self.steps[self.current_step_index]
    
    @property
    def is_first_step(self) -> bool:
        """Check if wizard is at the first step."""
        return self.current_step_index == 0
    
    @property
    def is_last_step(self) -> bool:
        """Check if wizard is at the last step."""
        return self.current_step_index == len(self.steps) - 1
    
    def get_data(self) -> Dict[str, Any]:
        """Get all wizard data."""
        return st.session_state.get(f"wizard_{self.name}_data", {})
    
    def set_data(self, key: str, value: Any):
        """Set a wizard data value."""
        if f"wizard_{self.name}_data" not in st.session_state:
            st.session_state[f"wizard_{self.name}_data"] = {}
        st.session_state[f"wizard_{self.name}_data"][key] = value
    
    def next_step(self):
        """Move to the next step."""
        if not self.is_last_step:
            self.current_step_index += 1
    
    def previous_step(self):
        """Move to the previous step."""
        if not self.is_first_step:
            self.current_step_index -= 1
    
    def go_to_step(self, index: int):
        """Go to a specific step by index."""
        if 0 <= index < len(self.steps):
            self.current_step_index = index
    
    def render(self):
        """Render the wizard interface."""
        # Display progress bar
        progress = self.current_step_index / (len(self.steps) - 1)
        st.progress(progress)
        
        # Display step number and title
        st.header(f"{self.current_step_index + 1}. {self.current_step.title}")
        st.write(self.current_step.description)
        
        # Render step content
        self.current_step.render_func()
        
        # Navigation buttons
        col1, col2, spacer, col3 = st.columns([1, 1, 3, 1])
        
        with col1:
            if not self.is_first_step:
                if st.button("â¬…ï¸ Ã–nceki", key=f"prev_{self.name}"):
                    self.previous_step()
                    st.experimental_rerun()
        
        with col2:
            if not self.is_first_step and not self.is_last_step:
                if st.button("ğŸ  Ana Sayfa", key=f"home_{self.name}"):
                    self.current_step_index = 0
                    st.experimental_rerun()
        
        with col3:
            if not self.is_last_step:
                next_button = st.button("Sonraki â¡ï¸", key=f"next_{self.name}")
                if next_button:
                    # Attempt to go to next step - validation should happen in the render_func
                    if not self.current_step.validation_error:
                        self.next_step()
                        st.experimental_rerun()
                    else:
                        st.error(self.current_step.validation_error)
            else:
                if st.button("ğŸ‰ Tamamla", key=f"finish_{self.name}", type="primary"):
                    st.balloons()
                    st.success("TÃ¼m adÄ±mlar tamamlandÄ±!")
                    # Additional completion logic can be added here

def show_step_indicator(wizard: Wizard):
    """
    Show a horizontal step indicator for the wizard.
    
    Args:
        wizard: The wizard object
    """
    cols = st.columns(len(wizard.steps))
    
    for i, step in enumerate(wizard.steps):
        with cols[i]:
            if i < wizard.current_step_index:
                # Completed step
                st.markdown(f"<div style='text-align: center; color: green;'>âœ“<br>{step.title}</div>", 
                           unsafe_allow_html=True)
            elif i == wizard.current_step_index:
                # Current step
                st.markdown(f"<div style='text-align: center; font-weight: bold;'>â— <br>{step.title}</div>", 
                           unsafe_allow_html=True)
            else:
                # Future step
                st.markdown(f"<div style='text-align: center; color: gray;'>â—‹<br>{step.title}</div>", 
                           unsafe_allow_html=True)
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/config/config.py
"""Configuration settings for the Real Estate Video Generator."""

import os
from dotenv import load_dotenv
import google.generativeai as genai
import streamlit as st

# Load environment variables from .env file
load_dotenv()

# Get API keys from environment variables
GOOGLE_MAPS_API_KEY = os.environ.get("GOOGLE_MAPS_API_KEY", "")
GOOGLE_PLACES_API_KEY = os.environ.get("GOOGLE_PLACES_API_KEY", "")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")
ELEVENLABS_API_KEY = os.environ.get("ELEVENLABS_API_KEY", "")
ELEVENLABS_VOICE_ID = os.environ.get("ELEVENLABS_VOICE_ID", "")

# Voice options - SÃ¶zlÃ¼k formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼
VOICE_OPTIONS = {
    "TxGEqnHWrfWFTfGW9XjX": "Erkek Sesi", 
    "ErXwobaYiN019PkySvjV": "KadÄ±n Sesi", 
    "21m00Tcm4TlvDq8ikWAM": "Alternatif Ses"
}
DEFAULT_VOICE = ELEVENLABS_VOICE_ID if ELEVENLABS_VOICE_ID in VOICE_OPTIONS else list(VOICE_OPTIONS.keys())[0]

# Define VOICE_LABELS (was missing)
VOICE_LABELS = VOICE_OPTIONS  # Using the same dictionary for labels

# Ensure video directory exists
VIDEO_DIR = "/home/jobbe/Desktop/Projects/emlak_web/vids"
os.makedirs(VIDEO_DIR, exist_ok=True)

# Configure Gemini API if key is available
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Function to initialize session state
def initialize_session_state():
    """Initialize Streamlit session state variables if they don't exist."""
    if "GOOGLE_MAPS_API_KEY" not in st.session_state:
        st.session_state["GOOGLE_MAPS_API_KEY"] = GOOGLE_MAPS_API_KEY
    if "GOOGLE_PLACES_API_KEY" not in st.session_state:
        st.session_state["GOOGLE_PLACES_API_KEY"] = GOOGLE_PLACES_API_KEY
    if "GEMINI_API_KEY" not in st.session_state:
        st.session_state["GEMINI_API_KEY"] = GEMINI_API_KEY
    if "ELEVENLABS_API_KEY" not in st.session_state:
        st.session_state["ELEVENLABS_API_KEY"] = ELEVENLABS_API_KEY
    if "enhance_colors" not in st.session_state:
        st.session_state["enhance_colors"] = True
    if "color_boost" not in st.session_state:
        st.session_state["color_boost"] = 1.5
    # Add Turkish labels
    if "voice_labels" not in st.session_state:
        st.session_state["voice_labels"] = VOICE_LABELS
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/integration/social_sharing.py
"""Social media sharing utilities."""

import streamlit as st
import qrcode
import base64
from io import BytesIO
from urllib.parse import quote
import os
from typing import Dict, Optional

def generate_qr_code(url: str, box_size: int = 10) -> str:
    """
    Generate QR code for a URL.
    
    Args:
        url: URL to encode in QR code
        box_size: QR code box size
        
    Returns:
        Base64 encoded image
    """
    qr = qrcode.QRCode(
        version=1,
        error_correction=qrcode.constants.ERROR_CORRECT_L,
        box_size=box_size,
        border=4,
    )
    qr.add_data(url)
    qr.make(fit=True)
    
    img = qr.make_image(fill_color="black", back_color="white")
    buffered = BytesIO()
    img.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    
    return img_str

def get_social_share_buttons(url: str, title: str, description: str = None) -> Dict[str, str]:
    """
    Generate HTML for social media sharing buttons.
    
    Args:
        url: URL to share
        title: Content title
        description: Content description
        
    Returns:
        Dictionary with HTML for each platform
    """
    encoded_url = quote(url)
    encoded_title = quote(title)
    encoded_description = quote(description or title)
    
    buttons = {
        "whatsapp": f"""
        <a href="https://api.whatsapp.com/send?text={encoded_title}%20{encoded_url}" 
           target="_blank" style="text-decoration:none;">
            <div style="background-color:#25D366;color:white;padding:8px 12px;
                       border-radius:4px;display:inline-flex;align-items:center;">
                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M13.601 2.326A7.854 7.854 0 0 0 7.994 0C3.627 0 .068 3.558.064 7.926c0 1.399.366 2.76 1.057 3.965L0 16l4.204-1.102a7.933 7.933 0 0 0 3.79.965h.004c4.368 0 7.926-3.558 7.93-7.93A7.898 7.898 0 0 0 13.6 2.326zM7.994 14.521a6.573 6.573 0 0 1-3.356-.92l-.24-.144-2.494.654.666-2.433-.156-.251a6.56 6.56 0 0 1-1.007-3.505c0-3.626 2.957-6.584 6.591-6.584a6.56 6.56 0 0 1 4.66 1.931a6.557 6.557 0 0 1 1.928 4.66c-.004 3.639-2.961 6.592-6.592 6.592zm3.615-4.934c-.197-.099-1.17-.578-1.353-.646-.182-.065-.315-.099-.445.099-.133.197-.513.646-.627.775-.114.133-.232.148-.43.05-.197-.1-.836-.308-1.592-.985-.59-.525-.985-1.175-1.103-1.372-.114-.198-.011-.304.088-.403.087-.088.197-.232.296-.346.1-.114.133-.198.198-.33.065-.134.034-.248-.015-.347-.05-.099-.445-1.076-.612-1.47-.16-.389-.323-.335-.445-.34-.114-.007-.247-.007-.38-.007a.729.729 0 0 0-.529.247c-.182.198-.691.677-.691 1.654c0 .977.71 1.916.81 2.049.098.133 1.394 2.132 3.383 2.992.47.205.84.326 1.129.418.475.152.904.129 1.246.08.38-.058 1.171-.48 1.338-.943.164-.464.164-.86.114-.943-.049-.084-.182-.133-.38-.232z"/>
                </svg>
                &nbsp;WhatsApp
            </div>
        </a>
        """,
        
        "telegram": f"""
        <a href="https://t.me/share/url?url={encoded_url}&text={encoded_title}" 
           target="_blank" style="text-decoration:none;">
            <div style="background-color:#0088cc;color:white;padding:8px 12px;
                       border-radius:4px;display:inline-flex;align-items:center;">
                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0zM8.287 5.906c-.778.324-2.334.994-4.666 2.01-.378.15-.577.298-.595.442-.03.243.275.339.69.47l.175.055c.408.133.958.288 1.243.294.26.006.549-.1.868-.32 2.179-1.471 3.304-2.214 3.374-2.23.05-.012.12-.026.166.016.047.041.042.12.037.141-.03.129-1.227 1.241-1.846 1.817-.193.18-.33.307-.358.336a8.154 8.154 0 0 1-.188.186c-.38.366-.664.64.015 1.088.327.216.589.393.85.571.284.194.568.387.936.629.093.06.183.125.27.187.331.236.63.448.997.414.214-.02.435-.22.547-.82.265-1.417.786-4.486.906-5.751a1.426 1.426 0 0 0-.013-.315.337.337 0 0 0-.114-.217.526.526 0 0 0-.31-.093c-.3.005-.763.166-2.984 1.09z"/>
                </svg>
                &nbsp;Telegram
            </div>
        </a>
        """,
        
        "facebook": f"""
        <a href="https://www.facebook.com/sharer/sharer.php?u={encoded_url}" 
           target="_blank" style="text-decoration:none;">
            <div style="background-color:#3b5998;color:white;padding:8px 12px;
                       border-radius:4px;display:inline-flex;align-items:center;">
                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
                </svg>
                &nbsp;Facebook
            </div>
        </a>
        """,
        
        "twitter": f"""
        <a href="https://twitter.com/intent/tweet?text={encoded_title}&url={encoded_url}" 
           target="_blank" style="text-decoration:none;">
            <div style="background-color:#1DA1F2;color:white;padding:8px 12px;
                       border-radius:4px;display:inline-flex;align-items:center;">
                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334 0-.14 0-.282-.006-.422A6.685 6.685 0 0 0 16 3.542a6.658 6.658 0 0 1-1.889.518 3.301 3.301 0 0 0 1.447-1.817 6.533 6.533 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.325 9.325 0 0 1-6.767-3.429 3.289 3.289 0 0 0 1.018 4.382A3.323 3.323 0 0 1 .64 6.575v.045a3.288 3.288 0 0 0 2.632 3.218 3.203 3.203 0 0 1-.865.115 3.23 3.23 0 0 1-.614-.057 3.283 3.283 0 0 0 3.067 2.277A6.588 6.588 0 0 1 .78 13.58a6.32 6.32 0 0 1-.78-.045A9.344 9.344 0 0 0 5.026 15z"/>
                </svg>
                &nbsp;Twitter
            </div>
        </a>
        """,
    }
    
    return buttons

def show_qr_code_with_download(url: str, title: str = "QR Kod") -> None:
    """
    Display QR code with download button.
    
    Args:
        url: URL to encode in QR code
        title: Title to display above QR code
    """
    qr_img = generate_qr_code(url)
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown(f"## {title}")
        st.markdown(f"""
        <img src="data:image/png;base64,{qr_img}" width="200"/>
        """, unsafe_allow_html=True)
        
        # Download button
        qr_data = f"data:image/png;base64,{qr_img}"
        download_button_str = f"""
        <a href="{qr_data}" download="qr_code.png">
            <button style="background-color:#4CAF50;color:white;padding:8px 16px;
                           border:none;border-radius:4px;cursor:pointer;">
                Ä°ndir
            </button>
        </a>
        """
        st.markdown(download_button_str, unsafe_allow_html=True)
    
    with col2:
        st.info(
            "Bu QR kodu tarayarak videoyu mobil cihazlarda izleyebilir veya paylaÅŸabilirsiniz. "
            "QR kodunu indirip basÄ±lÄ± materyallerde kullanabilirsiniz."
        )

def show_share_buttons(url: str, title: str, description: Optional[str] = None) -> None:
    """
    Display social share buttons in a Streamlit app.
    
    Args:
        url: URL to share
        title: Content title
        description: Content description
    """
    st.markdown("### PaylaÅŸ")
    
    buttons = get_social_share_buttons(url, title, description)
    
    # Display buttons in columns
    cols = st.columns(4)
    for i, (platform, button_html) in enumerate(buttons.items()):
        with cols[i % 4]:
            st.markdown(button_html, unsafe_allow_html=True)
    
    # Display share link
    st.text_input("DoÄŸrudan Link:", value=url, help="Bu linki kopyalayÄ±p paylaÅŸabilirsiniz")
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/integration/real_estate_platforms.py
"""Integration with popular real estate platforms."""

import streamlit as st
import json
import requests
import time
from typing import Dict, Any, List, Optional
import os

# Platform API configs - would normally be in a more secure location
PLATFORM_CONFIGS = {
    "sahibinden": {
        "name": "Sahibinden",
        "api_url": "https://api.example.com/sahibinden/v1",
        "logo": "https://www.sahibinden.com/favicon.ico"
    },
    "hepsiemlak": {
        "name": "Hepsiemlak",
        "api_url": "https://api.example.com/hepsiemlak/v1",
        "logo": "https://www.hepsiemlak.com/favicon.ico"
    },
    "emlakjet": {
        "name": "Emlakjet",
        "api_url": "https://api.example.com/emlakjet/v1",
        "logo": "https://www.emlakjet.com/favicon.ico"
    },
    "zingat": {
        "name": "Zingat",
        "api_url": "https://api.example.com/zingat/v1", 
        "logo": "https://www.zingat.com/favicon.ico"
    }
}

class RealEstatePlatformIntegration:
    """Base class for real estate platform integration."""
    
    def __init__(self, platform_id: str):
        """
        Initialize the integration.
        
        Args:
            platform_id: Platform ID from PLATFORM_CONFIGS
        """
        if platform_id not in PLATFORM_CONFIGS:
            raise ValueError(f"Unknown platform: {platform_id}")
        
        self.platform_id = platform_id
        self.config = PLATFORM_CONFIGS[platform_id]
        self.api_key = st.session_state.get(f"{platform_id.upper()}_API_KEY")
    
    def is_configured(self) -> bool:
        """Check if the API key is configured."""
        return bool(self.api_key)
    
    def upload_listing(self, property_data: Dict[str, Any], video_url: str) -> Dict[str, Any]:
        """
        Upload property listing to the platform (simulated).
        
        Args:
            property_data: Property details
            video_url: URL to the property video
            
        Returns:
            Response data
        """
        if not self.is_configured():
            return {"success": False, "error": "API key not configured"}
        
        # Simulate API call
        time.sleep(1)  # Simulate network delay
        
        # Return simulated response
        return {
            "success": True,
            "listing_id": f"{self.platform_id}_{int(time.time())}",
            "url": f"https://www.example.com/{self.platform_id}/listing/{int(time.time())}",
            "message": f"Listing uploaded successfully to {self.config['name']}"
        }
    
    def get_user_listings(self) -> List[Dict[str, Any]]:
        """
        Get user's existing listings (simulated).
        
        Returns:
            List of listing data
        """
        if not self.is_configured():
            return []
        
        # Simulate API call
        time.sleep(0.5)
        
        # Return simulated listings
        return [
            {
                "id": f"{self.platform_id}_{1000 + i}",
                "title": f"Ã–rnek Ä°lan {i+1}",
                "price": 500000 + (i * 100000),
                "location": "Ä°stanbul, TÃ¼rkiye",
                "url": f"https://www.example.com/{self.platform_id}/listing/{1000 + i}"
            }
            for i in range(3)
        ]

def get_available_platforms() -> List[Dict[str, Any]]:
    """
    Get list of available platforms with their configuration status.
    
    Returns:
        List of platform data
    """
    platforms = []
    
    for platform_id, config in PLATFORM_CONFIGS.items():
        api_key_exists = bool(st.session_state.get(f"{platform_id.upper()}_API_KEY"))
        
        platforms.append({
            "id": platform_id,
            "name": config["name"],
            "logo": config["logo"],
            "configured": api_key_exists
        })
    
    return platforms

def show_platform_setup_form() -> None:
    """Show form to set up platform API keys."""
    st.subheader("Emlak PlatformlarÄ± API AyarlarÄ±")
    
    with st.form("platform_api_keys"):
        for platform_id, config in PLATFORM_CONFIGS.items():
            current_key = st.session_state.get(f"{platform_id.upper()}_API_KEY", "")
            new_key = st.text_input(
                f"{config['name']} API AnahtarÄ±",
                value=current_key,
                type="password",
                help=f"{config['name']} platformu iÃ§in API anahtarÄ±nÄ±zÄ± girin"
            )
            if new_key:
                st.session_state[f"{platform_id.upper()}_API_KEY"] = new_key
        
        submitted = st.form_submit_button("API AnahtarlarÄ±nÄ± Kaydet")
        if submitted:
            st.success("API anahtarlarÄ± kaydedildi!")

def show_upload_form(property_data: Dict[str, Any], video_url: Optional[str] = None) -> None:
    """
    Show form to upload listing to platforms.
    
    Args:
        property_data: Property details
        video_url: URL to the property video
    """
    st.subheader("Emlak Ä°lanÄ±nÄ± YayÄ±nla")
    
    platforms = get_available_platforms()
    configured_platforms = [p for p in platforms if p["configured"]]
    
    if not configured_platforms:
        st.warning("HiÃ§bir platform yapÄ±landÄ±rÄ±lmamÄ±ÅŸ. LÃ¼tfen Ã¶nce API ayarlarÄ±nÄ± yapÄ±n.")
        if st.button("API AyarlarÄ±nÄ± GÃ¶ster"):
            show_platform_setup_form()
        return
    
    with st.form("publish_listing_form"):
        st.write("Ä°lanÄ±nÄ±zÄ± yayÄ±nlamak iÃ§in platform seÃ§in:")
        
        selected_platforms = []
        cols = st.columns(len(configured_platforms))
        
        for i, platform in enumerate(configured_platforms):
            with cols[i]:
                selected = st.checkbox(
                    f"{platform['name']}",
                    value=False,
                    key=f"publish_{platform['id']}"
                )
                
                if selected:
                    selected_platforms.append(platform["id"])
                
                st.image(platform["logo"], width=50)
        
        title = st.text_input("Ä°lan BaÅŸlÄ±ÄŸÄ±:", 
                           value=f"{property_data.get('property_type', '')} - {property_data.get('area', '')}mÂ² - {property_data.get('rooms', '')} Oda")
        
        description = st.text_area(
            "Ä°lan AÃ§Ä±klamasÄ±:", 
            value=property_data.get("description", ""),
            height=150
        )
        
        price = st.number_input(
            "Ä°lan FiyatÄ± (TL):", 
            min_value=0, 
            value=int(property_data.get("price", 0))
        )
        
        submitted = st.form_submit_button("Ä°lanÄ± YayÄ±nla")
        
        if submitted:
            if not selected_platforms:
                st.error("LÃ¼tfen en az bir platform seÃ§in!")
                return
                
            # Prepare listing data
            listing_data = {
                "title": title,
                "description": description,
                "price": price,
                "address": property_data.get("address", ""),
                "property_type": property_data.get("property_type", ""),
                "rooms": property_data.get("rooms", 0),
                "bathrooms": property_data.get("bathrooms", 0),
                "area": property_data.get("area", 0),
                "year_built": property_data.get("year_built", 0),
                "video_url": video_url
            }
            
            # Upload to each selected platform
            results = {}
            for platform_id in selected_platforms:
                with st.spinner(f"{PLATFORM_CONFIGS[platform_id]['name']} platformuna yÃ¼kleniyor..."):
                    integration = RealEstatePlatformIntegration(platform_id)
                    result = integration.upload_listing(listing_data, video_url)
                    results[platform_id] = result
            
            # Show results
            st.success("Ä°lan yayÄ±nlama iÅŸlemi tamamlandÄ±!")
            
            for platform_id, result in results.items():
                platform_name = PLATFORM_CONFIGS[platform_id]["name"]
                if result["success"]:
                    st.success(f"âœ… {platform_name}: {result['message']}")
                    st.markdown(f"ğŸ”— [Ä°lanÄ± GÃ¶rÃ¼ntÃ¼le]({result['url']})")
                else:
                    st.error(f"âŒ {platform_name}: {result['error']}")
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/image/image_processing.py
"""Image processing functions for satellite and street view images."""

import cv2
import numpy as np
import requests
import streamlit as st
from PIL import Image
from io import BytesIO
from streamlit_drawable_canvas import st_canvas

def enhance_image(image, boost_factor=1.5, preserve_colors=True):
    """Enhanced version of image processing"""
    try:
        if isinstance(image, Image.Image):
            img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        else:
            img_cv = image.copy()
            
        # Check if image is grayscale
        is_grayscale = len(img_cv.shape) == 2 or (len(img_cv.shape) == 3 and img_cv.shape[2] == 1)
        
        # Convert to LAB color space for better color enhancement
        if not is_grayscale:
            lab = cv2.cvtColor(img_cv, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            l = clahe.apply(l)
            
            # Merge channels
            lab = cv2.merge((l,a,b))
            img_cv = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        
        # Apply denoising
        img_cv = cv2.fastNlMeansDenoisingColored(img_cv, None, 10, 10, 7, 21)
        
        # Enhance sharpness
        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
        img_cv = cv2.filter2D(img_cv, -1, kernel)
        
        # Boost saturation if needed
        if boost_factor > 1.0:
            hsv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2HSV).astype("float32")
            (h, s, v) = cv2.split(hsv)
            s = np.clip(s * boost_factor, 0, 255)
            v = np.clip(v * 1.1, 0, 255)  # Slight brightness boost
            hsv = cv2.merge([h, s, v])
            img_cv = cv2.cvtColor(hsv.astype("uint8"), cv2.COLOR_HSV2BGR)
        
        # Convert back to PIL Image
        enhanced_pil = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))
        return enhanced_pil
    except Exception as e:
        st.warning(f"Image enhancement failed: {e}")
        return image

def fetch_satellite_image(address=None, lat=None, lng=None, zoom=18, size="640x640", maptype="satellite"):
    """
    Fetch satellite image from Google Maps Static API.
    
    Args:
        address: Address string (used if lat/lng not provided)
        lat, lng: Coordinates (preferred over address if provided)
        zoom: Zoom level (15-20)
        size: Image size (width x height)
        maptype: Map type (satellite, hybrid, roadmap)
        
    Returns:
        PIL Image object or None if failed
    """
    if not st.session_state.get("GOOGLE_MAPS_API_KEY"):
        st.error("Google Maps API key required!")
        return None
        
    base_url = "https://maps.googleapis.com/maps/api/staticmap"
    
    if lat is not None and lng is not None:
        location = f"{lat},{lng}"
    else:
        location = address
        
    params = {
        "center": location,
        "zoom": zoom,
        "size": size,
        "maptype": maptype,
        "key": st.session_state["GOOGLE_MAPS_API_KEY"]
    }
    
    try:
        response = requests.get(base_url, params=params)
        if response.status_code == 200:
            img = Image.open(BytesIO(response.content))
            enhance_colors = st.session_state.get('enhance_colors', True)
            color_boost = st.session_state.get('color_boost', 1.5)
            if enhance_colors:
                img = enhance_image(img, color_boost, preserve_colors=True)
            return img
        else:
            st.error(f"Failed to fetch satellite image: {response.status_code}")
            return None
    except Exception as e:
        st.error(f"Error fetching satellite image: {str(e)}")
        return None

def fetch_street_view_image(address=None, lat=None, lng=None, size="640x640", fov=90, heading=0, pitch=0):
    """
    Fetch street view image from Google Street View API.
    
    Args:
        address: Address string (used if lat/lng not provided)
        lat, lng: Coordinates (preferred over address if provided)
        size: Image size (width x height)
        fov: Field of view (degrees)
        heading: Camera heading (0-360)
        pitch: Camera pitch (-90 to 90)
        
    Returns:
        PIL Image object or None if failed
    """
    if not st.session_state.get("GOOGLE_MAPS_API_KEY"):
        return None
        
    base_url = "https://maps.googleapis.com/maps/api/streetview"
    
    if lat is not None and lng is not None:
        location = f"{lat},{lng}"
    else:
        location = address
        
    params = {
        "location": location,
        "size": size,
        "fov": fov,
        "heading": heading,
        "pitch": pitch,
        "key": st.session_state["GOOGLE_MAPS_API_KEY"]
    }
    
    try:
        response = requests.get(base_url, params=params)
        if response.status_code == 200:
            img = Image.open(BytesIO(response.content))
            enhance_colors = st.session_state.get('enhance_colors', True)
            color_boost = st.session_state.get('color_boost', 1.5)
            if enhance_colors:
                img = enhance_image(img, color_boost, preserve_colors=True)
            return img
        else:
            return None
    except Exception as e:
        st.warning(f"Error fetching street view: {str(e)}")
        return None

def draw_property_border(image, color, width=3, border_ratio=0.2):
    """
    Draw a border on a property image.
    
    Args:
        image: PIL Image object
        color: Border color as hex string (#RRGGBB)
        width: Border line width
        border_ratio: Ratio of border inset from edges (0.0-0.5)
    
    Returns:
        PIL Image with drawn border
    """
    img_array = np.array(image)
    h, w = img_array.shape[:2]
    
    # Convert hex color to RGB
    r = int(color[1:3], 16)
    g = int(color[3:5], 16)
    b = int(color[5:7], 16)
    
    # Draw rectangle (border_ratio inset from edges)
    x1, y1 = int(w * border_ratio), int(h * border_ratio)
    x2, y2 = int(w * (1 - border_ratio)), int(h * (1 - border_ratio))
    
    img_with_border = img_array.copy()
    cv2.rectangle(img_with_border, (x1, y1), (x2, y2), (b, g, r), width)
    
    return Image.fromarray(img_with_border)
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/image/enhance_integration.py
"""Integration helpers for image enhancement workflows."""

import streamlit as st
from PIL import Image
import os
import tempfile

# Import standard and deep enhancers
from modules.image.image_processing import enhance_image
from modules.image.deep_enhance import DeepImageEnhancer

# Singleton enhancer instance
_deep_enhancer = None

def get_deep_enhancer():
    """Get or create the deep enhancer singleton"""
    global _deep_enhancer
    if _deep_enhancer is None:
        _deep_enhancer = DeepImageEnhancer()
    return _deep_enhancer

def smart_enhance_image(image, use_deep_enhance=False, boost_factor=1.5, 
                       resolution_boost=True, denoise=True):
    """
    Smart image enhancement using either standard or deep learning methods
    
    Args:
        image: PIL Image to enhance
        use_deep_enhance: Whether to use deep learning enhancement
        boost_factor: Color boost factor for standard enhancement
        resolution_boost: Whether to boost resolution (deep enhance only)
        denoise: Whether to apply denoising (deep enhance only)
        
    Returns:
        Enhanced PIL Image
    """
    if use_deep_enhance:
        # Use deep learning enhancement
        enhancer = get_deep_enhancer()
        return enhancer.enhance(
            image, 
            resolution_boost=resolution_boost,
            remove_noise=denoise,
            sharpen=True
        )
    else:
        # Use standard enhancement
        return enhance_image(image, boost_factor=boost_factor)

def batch_enhance_images(images, progress_callback=None, **kwargs):
    """
    Enhance a batch of images with progress reporting
    
    Args:
        images: List of PIL Images
        progress_callback: Callback for reporting progress
        **kwargs: Parameters for smart_enhance_image
        
    Returns:
        List of enhanced PIL Images
    """
    enhanced_images = []
    total = len(images)
    
    for i, img in enumerate(images):
        if progress_callback:
            progress_callback(i / total, f"Enhancing image {i+1}/{total}")
            
        enhanced = smart_enhance_image(img, **kwargs)
        enhanced_images.append(enhanced)
        
    if progress_callback:
        progress_callback(1.0, "Enhancement complete")
        
    return enhanced_images
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/image/image_organizer.py
"""GÃ¶rÃ¼ntÃ¼ dÃ¼zenleme ve yeniden sÄ±ralama araÃ§larÄ±."""

import streamlit as st
from PIL import Image
import numpy as np
import base64
import io
import cv2  # Add missing import

def reorder_images(images, order=None):
    """
    GÃ¶rÃ¼ntÃ¼leri belirtilen sÄ±raya gÃ¶re yeniden dÃ¼zenler
    
    Args:
        images: GÃ¶rÃ¼ntÃ¼ listesi
        order: Yeni sÄ±ralama dizisi (None ise mevcut sÄ±ra korunur)
        
    Returns:
        Yeniden dÃ¼zenlenmiÅŸ gÃ¶rÃ¼ntÃ¼ listesi
    """
    if order is None or len(order) != len(images):
        return images
    
    return [images[i] for i in order]

def display_draggable_images(images, key_prefix="img"):
    """
    SÃ¼rÃ¼kle-bÄ±rak ile dÃ¼zenlenebilir gÃ¶rÃ¼ntÃ¼ arayÃ¼zÃ¼ gÃ¶sterir
    
    Args:
        images: GÃ¶rÃ¼ntÃ¼ listesi
        key_prefix: GÃ¶rÃ¼ntÃ¼ elementleri iÃ§in anahtar Ã¶neki
        
    Returns:
        Yeni gÃ¶rÃ¼ntÃ¼ sÄ±rasÄ±
    """
    st.markdown("### GÃ¶rÃ¼ntÃ¼leri DÃ¼zenleyin")
    st.info("GÃ¶rÃ¼ntÃ¼leri sÃ¼rÃ¼kleyip bÄ±rakarak sÄ±ralamayÄ± deÄŸiÅŸtirebilirsiniz.")
    
    # Her gÃ¶rÃ¼ntÃ¼ iÃ§in benzersiz bir id oluÅŸtur
    img_ids = [f"{key_prefix}_{i}" for i in range(len(images))]
    
    # GÃ¶rÃ¼ntÃ¼leri grid halinde gÃ¶ster
    cols = st.columns(3)
    order = list(range(len(images)))
    
    # CSS for drag and drop
    st.markdown("""
    <style>
    .draggable-img {
        cursor: move;
        border: 2px dashed transparent;
        transition: transform 0.2s;
        padding: 5px;
    }
    .draggable-img:hover {
        border-color: #0078ff;
        transform: scale(1.02);
    }
    </style>
    """, unsafe_allow_html=True)
    
    # JavaScript for drag and drop
    js = """
    <script>
    function setupDragDrop() {
        const imageContainers = document.querySelectorAll('.draggable-img-container');
        let draggedItem = null;
        
        imageContainers.forEach(container => {
            container.addEventListener('dragstart', function() {
                draggedItem = this;
                setTimeout(() => this.style.opacity = '0.4', 0);
            });
            
            container.addEventListener('dragend', function() {
                this.style.opacity = '1';
            });
            
            container.addEventListener('dragover', function(e) {
                e.preventDefault();
            });
            
            container.addEventListener('dragenter', function() {
                this.style.border = '2px dashed #0078ff';
            });
            
            container.addEventListener('dragleave', function() {
                this.style.border = '2px dashed transparent';
            });
            
            container.addEventListener('drop', function(e) {
                e.preventDefault();
                if (draggedItem !== this) {
                    // Swap containers
                    const allContainers = Array.from(document.querySelectorAll('.draggable-img-container'));
                    const fromIndex = allContainers.indexOf(draggedItem);
                    const toIndex = allContainers.indexOf(this);
                    
                    // Update new order in hidden input for Streamlit
                    const orderInput = document.getElementById('img-order-data');
                    let currentOrder = JSON.parse(orderInput.value);
                    
                    // Swap elements in order array
                    const temp = currentOrder[fromIndex];
                    currentOrder[fromIndex] = currentOrder[toIndex];
                    currentOrder[toIndex] = temp;
                    
                    // Update the hidden input
                    orderInput.value = JSON.stringify(currentOrder);
                    
                    // Visually swap elements
                    const parentContainer = this.parentNode;
                    const beforeElement = (fromIndex < toIndex) ? this.nextSibling : this;
                    parentContainer.insertBefore(draggedItem, beforeElement);
                    
                    // Trigger order update event
                    const event = new Event('orderUpdate');
                    orderInput.dispatchEvent(event);
                }
                this.style.border = '2px dashed transparent';
            });
        });
    }
    
    document.addEventListener('DOMContentLoaded', setupDragDrop);
    </script>
    """
    
    # Create hidden input to store order
    order_data = st.empty()
    
    # Display images with drag and drop
    for i, (img, img_id) in enumerate(zip(images, img_ids)):
        with cols[i % 3]:
            # Convert image to base64
            buffered = io.BytesIO()
            img.save(buffered, format="PNG")
            img_str = base64.b64encode(buffered.getvalue()).decode()
            
            # HTML for draggable image
            st.markdown(f"""
            <div class="draggable-img-container" draggable="true" id="container-{img_id}">
                <div class="draggable-img">
                    <img src="data:image/png;base64,{img_str}" width="100%" />
                    <p style="text-align:center;">GÃ¶rÃ¼ntÃ¼ {i+1}</p>
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    # Add JavaScript code at the end
    st.markdown(js, unsafe_allow_html=True)
    
    # Return the current order
    return order

def create_image_arranger(images):
    """
    Streamlit iÃ§in gÃ¶rÃ¼ntÃ¼ dÃ¼zenleyici bileÅŸen
    
    Args:
        images: DÃ¼zenlenecek gÃ¶rÃ¼ntÃ¼ listesi
        
    Returns:
        DÃ¼zenlenmiÅŸ gÃ¶rÃ¼ntÃ¼ listesi ve deÄŸiÅŸim bayraÄŸÄ±
    """
    st.subheader("GÃ¶rÃ¼ntÃ¼leri DÃ¼zenleyin")
    
    # DÃ¼zenleme tÃ¼rÃ¼ seÃ§imi
    edit_mode = st.radio("DÃ¼zenleme Modu:", 
                      ["Manuel SÄ±ralama", "Otomatik SÄ±ralama"],
                      horizontal=True)
    
    if edit_mode == "Manuel SÄ±ralama":
        # GÃ¶rÃ¼ntÃ¼leri gÃ¶ster ve manuel dÃ¼zenleme iÃ§in arayÃ¼z saÄŸla
        image_order = display_draggable_images(images)
        
        # SÄ±ralama butonlarÄ±
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("Ã–nemli OlanlarÄ± Ã–ne Ã‡Ä±kar"):
                # BÃ¼yÃ¼k ve daha detaylÄ± gÃ¶rÃ¼ntÃ¼leri Ã¶ne al
                image_sizes = [img.width * img.height for img in images]
                sorted_order = sorted(range(len(images)), key=lambda i: image_sizes[i], reverse=True)
                return reorder_images(images, sorted_order), True
        
        with col2:
            if st.button("Ufak GÃ¶rÃ¼ntÃ¼leri Sona Al"):
                # KÃ¼Ã§Ã¼k gÃ¶rÃ¼ntÃ¼leri sona al
                image_sizes = [img.width * img.height for img in images]
                sorted_order = sorted(range(len(images)), key=lambda i: image_sizes[i])
                return reorder_images(images, sorted_order), True
                
        with col3:
            if st.button("Orijinal SÄ±raya DÃ¶ndÃ¼r"):
                return images, True
    
    elif edit_mode == "Otomatik SÄ±ralama":
        # Otomatik sÄ±ralama seÃ§enekleri
        sort_option = st.selectbox(
            "SÄ±ralama Kriteri:",
            ["En Net Olanlar Ã–nce", "En Ä°yi Kompozisyonlar Ã–nce", "En Renkli Olanlar Ã–nce"]
        )
        
        if st.button("Otomatik SÄ±rala"):
            if sort_option == "En Net Olanlar Ã–nce":
                # GÃ¶rÃ¼ntÃ¼ netliÄŸine gÃ¶re sÄ±ralama (laplasyon filtresi)
                clarity_scores = []
                for img in images:
                    img_array = np.array(img.convert('L'))  # Gri tonlama
                    laplacian = cv2.Laplacian(img_array, cv2.CV_64F).var()
                    clarity_scores.append(laplacian)
                
                sorted_order = sorted(range(len(images)), key=lambda i: clarity_scores[i], reverse=True)
                return reorder_images(images, sorted_order), True
                
            elif sort_option == "En Ä°yi Kompozisyonlar Ã–nce":
                # Kural Ã¼Ã§te bir kompozisyonuna gÃ¶re sÄ±ralama
                composition_scores = []
                for img in images:
                    img_array = np.array(img)
                    # Basit bir kompozisyon puanÄ± hesapla
                    h, w = img_array.shape[:2]
                    center_region = img_array[h//4:3*h//4, w//4:3*w//4]
                    center_std = np.std(center_region)
                    composition_scores.append(center_std)
                
                sorted_order = sorted(range(len(images)), key=lambda i: composition_scores[i], reverse=True)
                return reorder_images(images, sorted_order), True
                
            elif sort_option == "En Renkli Olanlar Ã–nce":
                # Renk doygunluÄŸuna gÃ¶re sÄ±ralama
                saturation_scores = []
                for img in images:
                    img_hsv = np.array(img.convert('HSV'))
                    saturation = np.mean(img_hsv[:, :, 1])
                    saturation_scores.append(saturation)
                
                sorted_order = sorted(range(len(images)), key=lambda i: saturation_scores[i], reverse=True)
                return reorder_images(images, sorted_order), True
    
    return images, False
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/image/deep_enhance.py
"""Deep learning based image enhancement for real estate photography."""

import cv2
import numpy as np
from PIL import Image
import streamlit as st
import os
import tempfile

class DeepImageEnhancer:
    """
    Deep learning based image enhancement for real estate photography
    """
    
    def __init__(self, use_gpu=None):
        """
        Initialize the enhancer
        
        Args:
            use_gpu: Force GPU usage (None=auto-detect)
        """
        self.models_loaded = False
        self.model_sr = None  # Super resolution model
        self.model_denoise = None  # Denoising model
        
        # Auto-detect GPU
        if use_gpu is None:
            try:
                import torch
                self.use_gpu = torch.cuda.is_available()
            except ImportError:
                self.use_gpu = False
        else:
            self.use_gpu = use_gpu
            
        # Create model cache directory
        self.cache_dir = os.path.join(tempfile.gettempdir(), "deep_enhance_models")
        os.makedirs(self.cache_dir, exist_ok=True)
        
    def load_models(self):
        """Load deep learning models"""
        if self.models_loaded:
            return True
        
        try:
            # Try to load OpenCV's DNN Super Resolution model
            self.model_sr = cv2.dnn_superres.DnnSuperResImpl_create()
            
            # Download model if not in cache
            model_path = os.path.join(self.cache_dir, "ESPCN_x4.pb")
            if not os.path.exists(model_path):
                st.info("Downloading super-resolution model (first time only)...")
                import urllib.request
                urllib.request.urlretrieve(
                    "https://github.com/opencv/opencv_contrib/raw/master/modules/dnn_superres/models/ESPCN_x4.pb",
                    model_path
                )
            
            # Load the model
            self.model_sr.readModel(model_path)
            self.model_sr.setModel("espcn", 4)  # 4x upscaling
            
            # Set up denoising parameters
            self.models_loaded = True
            return True
            
        except Exception as e:
            st.warning(f"Could not load deep enhancement models: {e}")
            return False
    
    def enhance(self, image, resolution_boost=True, remove_noise=True, sharpen=True):
        """
        Enhance an image using multiple deep learning techniques
        
        Args:
            image: PIL Image or numpy array
            resolution_boost: Whether to enhance resolution
            remove_noise: Whether to remove noise
            sharpen: Whether to apply sharpening
            
        Returns:
            Enhanced PIL Image
        """
        # Convert to numpy array if PIL Image
        if isinstance(image, Image.Image):
            img = np.array(image)
            if img.shape[2] == 4:  # Handle RGBA
                img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)
        else:
            img = image.copy()
            if len(img.shape) == 2:  # Handle grayscale
                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
        
        # Ensure image is in RGB format for processing
        if img.shape[2] == 4:
            img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)
            
        # Get original size for later resizing
        original_h, original_w = img.shape[:2]
        
        # 1. Apply denoising if requested
        if remove_noise:
            # Use non-local means denoising
            img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)
        
        # 2. Apply super resolution if requested and models are loaded
        if resolution_boost and self.load_models():
            try:
                # Resize image to a reasonable size for SR model (max 1MP)
                max_mp = 1_000_000  # 1 megapixel
                scale_factor = 1.0
                
                if original_w * original_h > max_mp:
                    scale_factor = np.sqrt(max_mp / (original_w * original_h))
                    img = cv2.resize(img, 
                                    (int(original_w * scale_factor), 
                                     int(original_h * scale_factor)), 
                                    interpolation=cv2.INTER_AREA)
                
                # Apply super-resolution
                img = self.model_sr.upsample(img)
                
                # Resize back to slightly larger than original
                boost_factor = 1.2  # 20% resolution boost
                target_w = int(original_w * boost_factor)
                target_h = int(original_h * boost_factor)
                img = cv2.resize(img, (target_w, target_h), interpolation=cv2.INTER_LANCZOS4)
                
            except Exception as e:
                st.warning(f"Super-resolution failed, using standard processing: {e}")
                # Fallback to standard processing
                pass
        
        # 3. Apply sharpening if requested
        if sharpen:
            kernel = np.array([[-1, -1, -1],
                              [-1, 9, -1],
                              [-1, -1, -1]])
            img = cv2.filter2D(img, -1, kernel)
        
        # 4. Convert back to PIL
        return Image.fromarray(img)
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/image/__init__.py
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/geo/geo_utils.py
"""Geographic utilities for address geocoding and nearby place search."""

import streamlit as st
import requests
from utils.utils import calculate_distance  # DoÄŸrudan import edilebilir modÃ¼ller iÃ§in

def get_coordinates_from_address(address):
    """
    Get geographic coordinates from an address using Google Maps Geocoding API.
    
    Args:
        address: String address to geocode
        
    Returns:
        Tuple of (latitude, longitude, formatted_address) or (None, None, None) if failed
    """
    try:
        if not st.session_state.get("GOOGLE_MAPS_API_KEY"):
            st.error("Google Maps API key required!")
            return None, None, None
            
        url = "https://maps.googleapis.com/maps/api/geocode/json"
        params = {
            "address": address,
            "key": st.session_state["GOOGLE_MAPS_API_KEY"]
        }
        response = requests.get(url, params=params)
        data = response.json()
        
        if data["status"] == "OK":
            location = data["results"][0]["geometry"]["location"]
            return location["lat"], location["lng"], data["results"][0]["formatted_address"]
        else:
            st.error(f"Geocoding error: {data['status']}")
            return None, None, None
    except Exception as e:
        st.error(f"Error getting coordinates: {str(e)}")
        return None, None, None

def get_nearby_places(lat, lng, radius=1500, types=None):
    """
    Find nearby places of interest using Google Places API.
    
    Args:
        lat, lng: Coordinates to search around
        radius: Search radius in meters
        types: Types of places to find
        
    Returns:
        List of place dictionaries with name, type, distance, and rating
    """
    # Relatif import yerine doÄŸrudan import kullanÄ±yoruz
    # Ã–nceki: from utils.utils import calculate_distance
    
    if not st.session_state.get("GOOGLE_PLACES_API_KEY"):
        return []
    
    try:
        url = "https://maps.googleapis.com/maps/api/place/nearbysearch/json"
        params = {
            "location": f"{lat},{lng}",
            "radius": radius,
            "key": st.session_state["GOOGLE_PLACES_API_KEY"]
        }
        
        if types:
            params["type"] = types
            
        response = requests.get(url, params=params)
        data = response.json()
        
        places = []
        if data["status"] == "OK":
            for place in data["results"][:10]:  # Limit to top 10 places
                places.append({
                    "name": place.get("name", ""),
                    "type": place.get("types", [""])[0],
                    "distance": calculate_distance(lat, lng, 
                                             place["geometry"]["location"]["lat"], 
                                             place["geometry"]["location"]["lng"]),
                    "rating": place.get("rating", 0)
                })
        return places
    except Exception as e:
        st.warning(f"Error fetching nearby places: {str(e)}")
        return []
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/geo/__init__.py
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/audio/audio_generation.py
"""Audio generation functions using ElevenLabs text-to-speech API."""

import os
import tempfile
import streamlit as st
import requests
from moviepy.editor import AudioFileClip

def generate_audio_from_text(text, voice_id):
    """
    Generate audio from text using ElevenLabs API.
    
    Args:
        text: Text to convert to speech
        voice_id: ElevenLabs voice ID
        
    Returns:
        Path to the generated audio file or None if failed
    """
    if not st.session_state.get("ELEVENLABS_API_KEY"):
        st.error("ElevenLabs API anahtarÄ± gereklidir!")
        return None
            
    try:
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
        
        headers = {
            "Accept": "audio/mpeg",
            "Content-Type": "application/json",
            "xi-api-key": st.session_state["ELEVENLABS_API_KEY"]
        }
        
        data = {
            "text": text,
            "model_id": "eleven_multilingual_v2",
            "voice_settings": {
                "stability": 0.5,
                "similarity_boost": 0.75
            }
        }
        
        response = requests.post(url, json=data, headers=headers)
        
        if response.status_code == 200:
            # Create temporary file
            temp_dir = tempfile.mkdtemp()
            audio_path = os.path.join(temp_dir, "emlak_seslendirme.mp3")
            
            with open(audio_path, "wb") as f:
                f.write(response.content)
            
            return audio_path
        else:
            st.error(f"Ses oluÅŸturma hatasÄ±: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        st.error(f"Ses oluÅŸturma hatasÄ±: {str(e)}")
        return None

def get_audio_duration(audio_path):
    """
    Get the duration of an audio file in seconds.
    
    Args:
        audio_path: Path to audio file
        
    Returns:
        Duration in seconds
    """
    try:
        audio_clip = AudioFileClip(audio_path)
        duration = audio_clip.duration
        audio_clip.close()
        return duration
    except Exception as e:
        st.error(f"Error getting audio duration: {str(e)}")
        return 0
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/audio/__init__.py
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/audio/music_library.py
"""Music library and audio mixing utilities."""

import os
import tempfile
import requests
import streamlit as st
from pydub import AudioSegment
from pathlib import Path
import shutil

# Base directory for local music files
BASE_DIR = Path(__file__).parent.parent.parent
MUSIC_DIR = BASE_DIR / "static" / "music"
os.makedirs(MUSIC_DIR, exist_ok=True)

# Copy default music files from sample_music to music directory if they don't exist
def initialize_music_library():
    """Initialize music library by using local music files."""
    sample_dir = BASE_DIR / "static" / "sample_music"
    os.makedirs(sample_dir, exist_ok=True)
    
    # Define sample music files - these should be placed in the sample_music directory
    sample_files = {
        "elegant": "elegant_corporate.mp3",
        "inspiring": "inspiring_ambient.mp3", 
        "modern": "modern_corporate.mp3",
        "relaxing": "relaxing_ambient.mp3",
        "nature": "nature_sounds.mp3"
    }
    
    # Create simple empty sample files if they don't exist
    for key, filename in sample_files.items():
        sample_path = sample_dir / filename
        dest_path = MUSIC_DIR / filename
        
        # Copy if source exists and destination doesn't
        if not dest_path.exists():
            if sample_path.exists():
                shutil.copy2(sample_path, dest_path)
                st.info(f"MÃ¼zik dosyasÄ± kopyalandÄ±: {filename}")
            else:
                # Create a simple silent MP3 as a placeholder
                create_silent_audio(dest_path)
                st.info(f"Ã–rnek mÃ¼zik dosyasÄ± oluÅŸturuldu: {filename}")

def create_silent_audio(filepath, duration=10):
    """Create a silent audio file."""
    try:
        silent = AudioSegment.silent(duration=duration * 1000)  # duration in milliseconds
        silent.export(filepath, format="mp3")
    except Exception as e:
        st.warning(f"Ses dosyasÄ± oluÅŸturma hatasÄ±: {str(e)}")

# Voice options dictionary
MUSIC_OPTIONS = {
    "elegant": "Elegant Corporate",
    "inspiring": "Ä°lham Verici",
    "modern": "Modern Kurumsal",
    "relaxing": "RahatlatÄ±cÄ±", 
    "nature": "DoÄŸa Sesleri",
    "custom": "Kendi MÃ¼ziÄŸiniz",
    "no_music": "MÃ¼zik Yok"
}

def get_music_options():
    """
    Get available music options for background music.
    
    Returns:
        Dictionary with music options
    """
    return MUSIC_OPTIONS

def download_music(music_type):
    """
    Get the path to the music file.
    
    Args:
        music_type: Music type key from MUSIC_OPTIONS
        
    Returns:
        Path to music file or None if failed
    """
    if music_type not in MUSIC_OPTIONS or music_type in ["custom", "no_music"]:
        return None
        
    filename = f"{music_type}_music.mp3"
    # Map the key to actual filename based on our naming convention
    if music_type == "elegant":
        filename = "elegant_corporate.mp3"
    elif music_type == "inspiring":
        filename = "inspiring_ambient.mp3"
    elif music_type == "modern":
        filename = "modern_corporate.mp3"
    elif music_type == "relaxing":
        filename = "relaxing_ambient.mp3"
    elif music_type == "nature":
        filename = "nature_sounds.mp3"
    
    file_path = MUSIC_DIR / filename
    
    # If the file doesn't exist locally, create a simple silent file
    if not file_path.exists():
        try:
            create_silent_audio(file_path)
            st.info(f"MÃ¼zik dosyasÄ± oluÅŸturuldu: {filename}")
        except Exception as e:
            st.error(f"MÃ¼zik dosyasÄ± hazÄ±rlanamadÄ±: {str(e)}")
            return None
    
    return str(file_path)

def mix_audio(voice_path, music_path, music_volume=0.2):
    """
    Mix voice narration with background music.
    
    Args:
        voice_path: Path to voice audio file
        music_path: Path to music audio file
        music_volume: Music volume level (0.0-1.0)
        
    Returns:
        Path to mixed audio file or None if failed
    """
    try:
        # Load audio files
        voice = AudioSegment.from_file(voice_path)
        music = AudioSegment.from_file(music_path)
        
        # Adjust music volume
        music = music - (10 - int(music_volume * 10))  # Adjust volume level
        
        # Loop music to match voice duration if needed
        voice_duration_ms = len(voice)
        music_duration_ms = len(music)
        
        if voice_duration_ms > music_duration_ms:
            # Loop music to match voice length
            repeats = int(voice_duration_ms / music_duration_ms) + 1
            music = music * repeats
        
        # Trim music to voice length
        music = music[:voice_duration_ms]
        
        # Mix voice and music
        mixed = voice.overlay(music)
        
        # Save mixed audio
        temp_dir = tempfile.mkdtemp()
        output_path = os.path.join(temp_dir, "mixed_audio.mp3")
        mixed.export(output_path, format="mp3")
        
        return output_path
    except Exception as e:
        st.error(f"Ses karÄ±ÅŸtÄ±rma hatasÄ±: {str(e)}")
        return None

# Initialize music library at module import time
initialize_music_library()
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/__init__.py
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/text/text_generation.py
"""Text generation functions using Google's Gemini model."""

import streamlit as st
import google.generativeai as genai

def generate_property_description(property_data, nearby_places=None):
    """
    Generate a property description using Gemini API.
    
    Args:
        property_data: Dictionary with property information
        nearby_places: List of nearby places of interest
        
    Returns:
        Generated property description or None if failed
    """
    if not st.session_state.get("GEMINI_API_KEY"):
        st.error("Gemini API anahtarÄ± gereklidir!")
        return None
    
    try:
        # Configure Gemini API
        genai.configure(api_key=st.session_state["GEMINI_API_KEY"])
        model = genai.GenerativeModel('gemini-1.5-pro-latest')
        
        nearby_text = ""
        if nearby_places and len(nearby_places) > 0:
            nearby_text = "YakÄ±n Ã§evrede bulunan Ã¶nemli noktalar:\n"
            for place in sorted(nearby_places, key=lambda x: x['distance'])[:7]:  # Sort by distance and limit
                nearby_text += f"- {place['name']} ({place['type'].replace('_', ' ')}) - {place['distance']} metre\n"
        
        prompt = f"""
        AÅŸaÄŸÄ±daki bilgilere dayanarak TÃ¼rkÃ§e dilinde bir emlak ilanÄ± metni oluÅŸtur.
        Metin profesyonel, Ã§ekici ve bilgilendirici olmalÄ±dÄ±r.
        Metin normal bir hÄ±zda okunduÄŸunda yaklaÅŸÄ±k 45-60 saniye sÃ¼rmeli (maksimum 600 karakter).
        
        Adres: {property_data['address']}
        Emlak Tipi: {property_data['property_type']}
        Oda SayÄ±sÄ±: {property_data['rooms']}
        Banyo SayÄ±sÄ±: {property_data['bathrooms']}
        Alan: {property_data['area']} mÂ²
        Fiyat: {property_data['price']:,} TL
        YapÄ±m YÄ±lÄ±: {property_data['year_built']}
        Ã–zel Ã–zellikler: {property_data['special_features']}
        
        {nearby_text}
        
        Mevcut AÃ§Ä±klama: {property_data['description']}
        
        Ã‡evredeki alanlardan, konum avantajlarÄ±ndan ve emlaÄŸÄ±n deÄŸerini artÄ±ran Ã¶zelliklerden bahset.
        LÃ¼tfen sadece metni dÃ¶ndÃ¼r, baÅŸka aÃ§Ä±klama ekleme.
        """
        
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        st.error(f"Metin oluÅŸturma hatasÄ±: {str(e)}")
        return None
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/text/__init__.py
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/video/advanced_stabilization.py
"""Advanced video stabilization techniques for smoother real estate videos."""

import cv2
import numpy as np
import streamlit as st

def stabilize_video_sequence(frames, smoothing_window=30):
    """
    Apply advanced stabilization to a sequence of frames
    
    Args:
        frames: List of frames to stabilize
        smoothing_window: Smoothing window size for trajectory
    
    Returns:
        List of stabilized frames
    """
    n_frames = len(frames)
    if n_frames < 3:
        return frames  # Not enough frames to stabilize
        
    # Get frame dimensions
    h, w = frames[0].shape[:2]
    
    # Pre-allocate trajectory and smoothed trajectory arrays
    trajectory = np.zeros((n_frames-1, 3), np.float32)  # dx, dy, da (angle)
    
    # Track feature points across frames
    prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)
    prev_pts = cv2.goodFeaturesToTrack(prev_gray, maxCorners=200, qualityLevel=0.01, minDistance=30, blockSize=3)
    
    if prev_pts is None or len(prev_pts) < 10:
        return frames  # Not enough feature points
        
    # Progress indicator
    progress_placeholder = st.empty()
    
    # Calculate frame-to-frame transformations
    for i in range(1, n_frames):
        curr_gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)
        
        # Update progress
        if i % 5 == 0:
            progress_placeholder.text(f"Stabilizing frames: {i}/{n_frames}")
            
        # Calculate optical flow
        curr_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_pts, None)
        
        # Filter only valid points
        idx = np.where(status == 1)[0]
        if len(idx) < 10:  # Not enough matching points
            prev_gray = curr_gray.copy()
            prev_pts = cv2.goodFeaturesToTrack(prev_gray, maxCorners=200, qualityLevel=0.01, minDistance=30, blockSize=3)
            continue
            
        prev_pts_valid = prev_pts[idx].reshape(-1, 2)
        curr_pts_valid = curr_pts[idx].reshape(-1, 2)
        
        # Estimate rigid transformation
        m = cv2.estimateAffinePartial2D(prev_pts_valid, curr_pts_valid)[0]
        
        if m is None:  # Transformation estimation failed
            trajectory[i-1] = trajectory[i-2] if i > 1 else np.zeros(3)
        else:
            # Extract translation and rotation
            dx = m[0, 2]
            dy = m[1, 2]
            da = np.arctan2(m[1, 0], m[0, 0])
            trajectory[i-1] = [dx, dy, da]
        
        # Update for next iteration
        prev_gray = curr_gray.copy()
        prev_pts = curr_pts_valid.reshape(-1, 1, 2)
    
    # Smooth trajectory
    smoothed_trajectory = smooth_trajectory(trajectory, smoothing_window)
    
    # Calculate difference
    difference = smoothed_trajectory - trajectory
    
    # Apply transformation
    stabilized_frames = []
    stabilized_frames.append(frames[0])  # First frame remains unchanged
    
    for i in range(1, n_frames):
        # Get transformation matrix
        dx, dy, da = difference[i-1]
        
        # Create transformation matrix
        m = np.zeros((2, 3), np.float32)
        m[0, 0] = np.cos(da)
        m[0, 1] = -np.sin(da)
        m[1, 0] = np.sin(da)
        m[1, 1] = np.cos(da)
        m[0, 2] = dx
        m[1, 2] = dy
        
        # Apply transformation
        frame_stabilized = cv2.warpAffine(frames[i], m, (w, h), borderMode=cv2.BORDER_REFLECT)
        stabilized_frames.append(frame_stabilized)
        
        # Update progress
        if i % 5 == 0:
            progress_placeholder.text(f"Applying stabilization: {i}/{n_frames}")
    
    progress_placeholder.empty()
    return stabilized_frames

def smooth_trajectory(trajectory, window_size):
    """
    Smooth trajectory using moving average
    
    Args:
        trajectory: Array of trajectory vectors
        window_size: Window size for smoothing
    
    Returns:
        Smoothed trajectory array
    """
    smoothed = np.copy(trajectory)
    
    # Handle edge cases for small trajectories
    if len(trajectory) <= window_size:
        return smoothed
        
    # Apply moving average
    for i in range(len(trajectory)):
        start = max(0, i - window_size // 2)
        end = min(len(trajectory), i + window_size // 2 + 1)
        
        # Calculate average in window
        smoothed[i] = np.mean(trajectory[start:end], axis=0)
    
    return smoothed
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/video/video_generation.py
"""Video generation and effects functions.""" 

import os
import tempfile
import cv2
import numpy as np
import streamlit as st
from PIL import Image
import traceback
import gc
from moviepy.editor import ImageSequenceClip, AudioFileClip, VideoFileClip
import time

# Import new modules - ensure they exist
try:
    from modules.video.advanced_stabilization import stabilize_video_sequence
except ImportError:
    # Fallback if module doesn't exist
    def stabilize_video_sequence(frames, smoothing_window=30):
        return frames

def update_progress(progress_callback, percentage, message):
    """Safely update progress with valid percentage"""
    if progress_callback:
        # Ensure percentage is between 0-1
        safe_percentage = max(0.0, min(1.0, percentage))
        progress_callback(safe_percentage, message)
        print(f"Progress: {message} ({safe_percentage:.1%})")

def create_frame_effect(image, n_frames, effect_type="zoom", zoom_in=True, pan_direction="right"):
    """Create effect frames for a single image"""
    img_array = np.array(image)
    h, w = img_array.shape[:2]
    frames = []
    
    if effect_type == "zoom":
        # Use smooth easing function for zoom
        zoom_range = np.array([1 - np.cos(x * np.pi / 2) for x in np.linspace(0, 1, n_frames)])
        zoom_range = 1.0 + (0.3 if zoom_in else -0.3) * zoom_range
        
        for factor in zoom_range:
            new_h, new_w = int(h / factor), int(w / factor)
            y1, x1 = (h - new_h) // 2, (w - new_w) // 2
            y2, x2 = y1 + new_h, x1 + new_w
            
            if 0 <= y1 < y2 <= h and 0 <= x1 < x2 <= w:
                # Apply Gaussian blur for smoother transitions
                cropped = img_array[y1:y2, x1:x2]
                if factor != 1.0:
                    blur_size = int(max(1, min(3, abs(1-factor) * 5)))
                    cropped = cv2.GaussianBlur(cropped, (blur_size*2+1, blur_size*2+1), 0)
                frame = cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LANCZOS4)
                frames.append(frame)
    
    elif effect_type == "pan":
        # Use smooth easing for pan effect
        max_shift = w // 4 if pan_direction in ["right", "left"] else h // 4
        shifts = np.array([1 - np.cos(x * np.pi / 2) for x in np.linspace(0, 1, n_frames)])
        shifts = shifts * max_shift
        
        if pan_direction in ["right", "down"]:
            shifts = shifts[::-1]
            
        for shift in shifts:
            shift = int(shift)
            # Create translation matrix
            if pan_direction in ["right", "left"]:
                M = np.float32([[1, 0, -shift], [0, 1, 0]])
            else:
                M = np.float32([[1, 0, 0], [0, 1, -shift]])
                
            # Apply perspective transform for more natural movement
            frame = cv2.warpAffine(img_array, M, (w, h), 
                                 flags=cv2.INTER_LANCZOS4,
                                 borderMode=cv2.BORDER_REFLECT)
            frames.append(frame)
    
    # Apply stabilization if needed
    if len(frames) > 2:
        stabilized_frames = []
        prev_frame = frames[0]
        for frame in frames[1:]:
            # Calculate and apply minimal stabilization
            try:
                orb = cv2.ORB_create()
                kp1, des1 = orb.detectAndCompute(prev_frame, None)
                kp2, des2 = orb.detectAndCompute(frame, None)
                
                if des1 is not None and des2 is not None:
                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
                    matches = bf.match(des1, des2)
                    
                    if matches:
                        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
                        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)
                        
                        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
                        if M is not None:
                            frame = cv2.warpPerspective(frame, M, (w, h))
            except Exception:
                pass  # Fall back to original frame if stabilization fails
                
            stabilized_frames.append(frame)
            prev_frame = frame
        
        frames = [frames[0]] + stabilized_frames
    
    return frames

def apply_cinematic_effects(frames, effect_type="cinematic"):
    """
    Apply cinematic color grading and visual effects
    
    Args:
        frames: List of frames
        effect_type: Type of cinematic effect (cinematic, warm, cool, vintage)
        
    Returns:
        List of processed frames
    """
    processed_frames = []
    
    # Define color grading LUTs for different styles
    lut_intensity = 0.7  # Intensity of effect (0-1)
    
    for frame in frames:
        if effect_type == "warm":
            # Warm cinematic look
            frame_lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(frame_lab)
            # Boost red/yellow tones
            a = cv2.add(a, 10)
            b = cv2.add(b, 15)
            frame_lab = cv2.merge([l, a, b])
            frame = cv2.cvtColor(frame_lab, cv2.COLOR_LAB2BGR)
            
            # Add slight vignette
            frame = apply_vignette(frame, 0.3)
            
        elif effect_type == "cool":
            # Cool cinematic look
            frame_lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(frame_lab)
            # Boost cool tones
            a = cv2.subtract(a, 10)
            b = cv2.subtract(b, 10)
            frame_lab = cv2.merge([l, a, b])
            frame = cv2.cvtColor(frame_lab, cv2.COLOR_LAB2BGR)
            
        elif effect_type == "vintage":
            # Vintage look
            frame = apply_vintage_effect(frame)
            
        else:  # Default cinematic
            # Standard cinematic grade (slight contrast boost, richer shadows)
            frame = apply_cinematic_grade(frame)
            
        processed_frames.append(frame)
        
    return processed_frames

def apply_vignette(image, intensity=0.5):
    """Apply a vignette effect to an image"""
    height, width = image.shape[:2]
    
    # Create a radial gradient mask
    x = np.linspace(-1, 1, width)
    y = np.linspace(-1, 1, height)
    x_grid, y_grid = np.meshgrid(x, y)
    
    # Calculate radial distance from center
    radius = np.sqrt(x_grid**2 + y_grid**2)
    
    # Create vignette mask
    mask = 1 - np.clip(radius - 0.5, 0, 1) * intensity * 1.5
    mask = mask.reshape(height, width, 1)
    
    # Apply mask to image
    vignette = image * mask
    
    return vignette.astype(np.uint8)

def apply_cinematic_grade(image):
    """Apply basic cinematic color grading"""
    # Convert to float for processing
    img_float = image.astype(np.float32) / 255.0
    
    # Lift shadows slightly
    shadows = 0.05
    img_float = img_float * (1 - shadows) + shadows
    
    # Increase contrast with S-curve
    img_float = 0.5 + 1.2 * (img_float - 0.5)
    
    # Boost saturation slightly
    hsv = cv2.cvtColor(np.clip(img_float, 0, 1).astype(np.float32), cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    s = s * 1.1  # Boost saturation by 10%
    s = np.clip(s, 0, 1)
    hsv = cv2.merge([h, s, v])
    
    # Convert back to BGR
    img_graded = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    
    # Convert back to uint8
    img_graded = np.clip(img_graded * 255, 0, 255).astype(np.uint8)
    
    return img_graded

def apply_vintage_effect(image):
    """Apply a vintage film effect"""
    # Create sepia tone effect
    sepia = np.array([[0.393, 0.769, 0.189],
                     [0.349, 0.686, 0.168],
                     [0.272, 0.534, 0.131]])
                     
    # Apply sepia transformation
    sepia_img = cv2.transform(image, sepia)
    
    # Add noise to simulate film grain
    noise = np.random.normal(0, 5, image.shape).astype(np.uint8)
    vintage = cv2.add(sepia_img, noise)
    
    # Add slight vignette
    vintage = apply_vignette(vintage, 0.4)
    
    return vintage

def optimize_image_for_video(image, target_width, target_height):
    """
    Optimize an image for video processing to reduce memory usage
    
    Args:
        image: PIL Image
        target_width: Desired width
        target_height: Desired height
        
    Returns:
        Optimized numpy array in BGR format
    """
    try:
        # Convert PIL to numpy if needed
        if isinstance(image, Image.Image):
            # Resize image to target dimensions
            image = image.resize((target_width, target_height), Image.LANCZOS)
            
            # Convert to RGB if in another mode
            if image.mode != 'RGB':
                image = image.convert('RGB')
                
            # Convert to numpy array
            img_array = np.array(image)
            
            # Convert RGB to BGR for OpenCV
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        else:
            # Already numpy array, just resize
            img_array = cv2.resize(image, (target_width, target_height))
            
            # Ensure BGR format
            if len(img_array.shape) == 3 and img_array.shape[2] == 4:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2BGR)
            elif len(img_array.shape) == 2:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)
        
        return img_array
    except Exception as e:
        print(f"Image optimization error: {e}")
        traceback.print_exc()
        
        # Fallback: create a blank image with text
        blank = np.ones((target_height, target_width, 3), dtype=np.uint8) * 128
        cv2.putText(blank, "Image Error", (50, target_height//2), 
                  cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        return blank

def generate_video(images, audio_path, transition_type, fps, quality, temp_dir, final_path, progress_callback=None):
    """Generate video with progress tracking"""
    try:
        if progress_callback:
            progress_callback(0.01, "Video oluÅŸturma baÅŸlatÄ±lÄ±yor...")
            
        # Create temporary working directory
        work_dir = os.path.join(temp_dir, f'video_work_{time.strftime("%Y%m%d-%H%M%S")}')
        os.makedirs(work_dir, exist_ok=True)
        
        # Process images
        if progress_callback:
            progress_callback(0.1, "GÃ¶rÃ¼ntÃ¼ler iÅŸleniyor...")
            
        processed_images = []
        for i, img in enumerate(images):
            temp_img_path = os.path.join(work_dir, f'frame_{i}.jpg')
            img.save(temp_img_path)
            processed_images.append(temp_img_path)
            if progress_callback:
                progress_callback(0.1 + (0.4 * (i/len(images))), f"GÃ¶rÃ¼ntÃ¼ {i+1}/{len(images)} iÅŸleniyor...")
        
        # Generate video
        if progress_callback:
            progress_callback(0.5, "Video oluÅŸturuluyor...")
            
        
        
    except Exception as e:
        if progress_callback:
            progress_callback(0, f"Hata: {str(e)}")
        raise e

def generate_video_with_ffmpeg(images, audio_path, fps=30, quality="normal", progress_callback=None):
    """
    Fallback method to generate video using FFmpeg directly via moviepy
    
    Args:
        images: List of PIL images
        audio_path: Path to audio file
        fps: Frames per second
        quality: Video quality (normal/high)
        progress_callback: Callback for progress reporting
        
    Returns:
        Path to generated video
    """
    from moviepy.editor import ImageSequenceClip, AudioFileClip
    import tempfile
    import os
    import numpy as np
    
    # Progress tracking
    progress_text = st.empty()
    progress_bar = st.progress(0.20)  # Start at 20%
    
    def update_progress(percent, message):
        if progress_callback:
            progress_callback(percent, message)
        progress_bar.progress(percent)
        progress_text.text(message)
    
    # Create temp directory
    temp_dir = tempfile.mkdtemp()
    final_path = os.path.join(temp_dir, "final_video.mp4")
    
    # Convert all images to numpy arrays
    if quality == "high":
        target_size = (1920, 1080)
        bitrate = "4000k"
    else:
        target_size = (1280, 720)
        bitrate = "2000k"
    
    # Process images
    update_progress(0.30, "GÃ¶rÃ¼ntÃ¼ler hazÄ±rlanÄ±yor... (30%)")
    
    # Process images with better memory management
    frames = []
    for i, img in enumerate(images):
        # Update progress: 30% to 60% for image processing
        current_progress = 0.30 + (0.30 * (i / len(images)))
        remaining_percent = 100 - int(current_progress * 100)
        update_progress(
            current_progress, 
            f"GÃ¶rÃ¼ntÃ¼ hazÄ±rlanÄ±yor {i+1}/{len(images)}... (Kalan: %{remaining_percent})"
        )
        
        try:
            if isinstance(img, Image.Image):
                img = img.resize(target_size, Image.LANCZOS)
                img_array = np.array(img.convert('RGB'))
                frames.append(img_array)
            else:
                # Already numpy array
                img_array = cv2.resize(img, target_size)
                if len(img_array.shape) == 2:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
                elif img_array.shape[2] == 4:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
                frames.append(img_array)
                
            # Force memory cleanup after each image
            if i % 2 == 0:
                optimize_memory_usage()
                
        except Exception as e:
            print(f"Error processing image {i}: {str(e)}")
            # Continue with next image
    
    # Create video clip
    update_progress(0.60, "Video klip hazÄ±rlanÄ±yor... (60%)")
    clip = ImageSequenceClip(frames, fps=fps)
    
    # Add audio
    update_progress(0.70, "Ses ekleniyor... (70%)")
    
    # Check audio file existence
    if not os.path.exists(audio_path):
        update_progress(0.70, "Ses dosyasÄ± bulunamadÄ±! Sessiz video oluÅŸturuluyor...")
        # Create a silent video
        silent_path = os.path.join(temp_dir, "silent.mp4")
        clip.write_videofile(
            silent_path,
            codec="libx264",
            audio_codec=None,
            bitrate=bitrate,
            fps=fps,
            threads=2,
            logger=None
        )
        return silent_path
    
    audio = AudioFileClip(audio_path)
    clip = clip.set_audio(audio)
    
    # Write video file with explicit parameters
    update_progress(0.80, "Video oluÅŸturuluyor ve kaydediliyor... (80%)")
    
    # Capture potential moviepy errors
    try:
        clip.write_videofile(
            final_path,
            codec="libx264",
            audio_codec="aac",
            bitrate=bitrate,
            fps=fps,
            threads=2,
            logger=None  # Suppress moviepy output
        )
    except Exception as e:
        print(f"MoviePy write error: {str(e)}")
        
        # Try with more conservative settings
        update_progress(0.85, "Alternatif video oluÅŸturma yÃ¶ntemi deneniyor...")
        try:
            clip.write_videofile(
                final_path,
                codec="libx264",
                audio_codec="aac",
                bitrate="1000k",
                fps=24,
                threads=1,
                logger=None
            )
        except Exception as e2:
            print(f"Second MoviePy write error: {str(e2)}")
            raise
    
    update_progress(1.0, "TamamlandÄ±! (100%)")
    
    # Clean up
    try:
        clip.close()
        audio.close()
    except:
        pass
    
    return final_path

def optimize_memory_usage():
    """Force garbage collection and free memory"""
    import gc
    import sys
    
    # Force garbage collection
    collected = gc.collect()
    
    # Try to release more memory if on Linux
    if sys.platform.startswith('linux'):
        try:
            # Use malloc_trim to release memory back to OS
            import ctypes
            ctypes.CDLL('libc.so.6').malloc_trim(0)
        except:
            pass
    
    return collected
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/video/preview_utils.py
"""Utilities for generating video previews."""

import streamlit as st
import tempfile
import os
from PIL import Image
import numpy as np
import io
import base64

def create_gif_preview(images, duration=500, max_size=(400, 300)):
    """
    Create a GIF preview from a list of images.
    
    Args:
        images: List of PIL images
        duration: Milliseconds per frame
        max_size: Maximum dimensions (width, height)
        
    Returns:
        Path to generated GIF file
    """
    try:
        # Resize images to consistent size
        resized_images = []
        for img in images:
            # Make a copy to avoid modifying original
            img_copy = img.copy()
            img_copy.thumbnail(max_size, Image.LANCZOS)
            resized_images.append(img_copy)
        
        # Create temporary file
        temp_dir = tempfile.mkdtemp()
        gif_path = os.path.join(temp_dir, "preview.gif")
        
        # Save as GIF
        resized_images[0].save(
            gif_path,
            save_all=True,
            append_images=resized_images[1:],
            optimize=True,
            duration=duration,
            loop=0
        )
        
        return gif_path
    except Exception as e:
        st.error(f"GIF Ã¶nizleme oluÅŸturma hatasÄ±: {str(e)}")
        return None

def show_video_preview(images, audio_path=None):
    """
    Show a preview of what the video will look like.
    
    Args:
        images: List of images to include in the preview
        audio_path: Optional path to audio file
    """
    st.subheader("Video Ã–nizleme")
    
    # Create tabs for different preview options
    preview_tab, images_tab = st.tabs(["Animasyon Ã–nizleme", "TÃ¼m GÃ¶rÃ¼ntÃ¼ler"])
    
    with preview_tab:
        col1, col2 = st.columns([3, 1])
        
        with col1:
            if len(images) > 1:
                # Create and display GIF preview
                gif_path = create_gif_preview(images[:min(8, len(images))])
                if gif_path:
                    st.image(gif_path, use_container_width=True)
                    st.caption("Animasyon Ã¶rneÄŸi (gerÃ§ek video daha yÃ¼ksek kalitede olacak)")
            else:
                st.image(images[0], use_container_width=True)
                st.caption("Ã–nizleme iÃ§in en az 2 gÃ¶rÃ¼ntÃ¼ gereklidir")
        
        with col2:
            st.write("**Video Ä°Ã§eriÄŸi:**")
            st.write(f"- {len(images)} gÃ¶rÃ¼ntÃ¼")
            if audio_path:
                st.write("- Sesli anlatÄ±m")
                st.audio(audio_path)
            
            transition_type = st.session_state.get('transition_type', 'YakÄ±nlaÅŸma')
            st.write(f"- GeÃ§iÅŸ efekti: {transition_type}")
            
            quality = "1080p" if st.session_state.get('video_quality') == "high" else "720p"
            st.write(f"- Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k: {quality}")
    
    with images_tab:
        # Show all images in a grid
        cols = st.columns(4)
        for i, img in enumerate(images):
            with cols[i % 4]:
                st.image(img, caption=f"GÃ¶rÃ¼ntÃ¼ {i+1}", use_container_width=True)
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/video/__init__.py
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/modules/video/overlay_tools.py
"""Video overlay tools for adding text, logos and watermarks."""

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import streamlit as st
import os
import tempfile

def add_text_overlay(image, text, position="bottom", font_size=24, color=(255, 255, 255), 
                    bg_opacity=0.5, padding=10, font_path=None):
    """
    GÃ¶rÃ¼ntÃ¼ye metin ekler
    
    Args:
        image: PIL gÃ¶rÃ¼ntÃ¼sÃ¼
        text: Eklenecek metin
        position: Metin konumu ("top", "bottom", "top-left", etc.)
        font_size: YazÄ± tipi boyutu
        color: RGB olarak yazÄ± rengi
        bg_opacity: Arka plan opaklÄ±ÄŸÄ± (0-1)
        padding: Metin etrafÄ±ndaki dolgu miktarÄ±
        font_path: Ã–zel yazÄ± tipi dosya yolu (None ise varsayÄ±lan)
        
    Returns:
        Metin eklenmiÅŸ PIL gÃ¶rÃ¼ntÃ¼sÃ¼
    """
    # Orijinal gÃ¶rÃ¼ntÃ¼ boyutlarÄ±
    img = image.copy()
    width, height = img.size
    draw = ImageDraw.Draw(img)
    
    # YazÄ± tipini ayarla
    try:
        if font_path and os.path.exists(font_path):
            font = ImageFont.truetype(font_path, font_size)
        else:
            # VarsayÄ±lan yazÄ± tipi
            font = ImageFont.load_default()
            font_size = 16  # VarsayÄ±lan yazÄ± tipi iÃ§in kÃ¼Ã§Ã¼lt
    except Exception as e:
        st.warning(f"YazÄ± tipi yÃ¼klenemedi, varsayÄ±lan kullanÄ±lÄ±yor: {str(e)}")
        font = ImageFont.load_default()
        font_size = 16
    
    # Metin boyutunu hesapla
    text_width, text_height = draw.textsize(text, font=font) if hasattr(draw, 'textsize') else (font_size * len(text) * 0.6, font_size * 1.5)
    
    # Metin konumunu belirle
    if position == "top":
        text_position = ((width - text_width) / 2, padding)
    elif position == "bottom":
        text_position = ((width - text_width) / 2, height - text_height - padding)
    elif position == "top-left":
        text_position = (padding, padding)
    elif position == "top-right":
        text_position = (width - text_width - padding, padding)
    elif position == "bottom-left":
        text_position = (padding, height - text_height - padding)
    elif position == "bottom-right":
        text_position = (width - text_width - padding, height - text_height - padding)
    elif position == "center":
        text_position = ((width - text_width) / 2, (height - text_height) / 2)
    else:
        text_position = ((width - text_width) / 2, height - text_height - padding)
    
    # Saydam arka plan oluÅŸtur
    overlay = Image.new('RGBA', img.size, (0, 0, 0, 0))
    overlay_draw = ImageDraw.Draw(overlay)
    
    # Metin arka planÄ± Ã§iz
    bg_color = (0, 0, 0, int(255 * bg_opacity))
    overlay_draw.rectangle(
        [
            text_position[0] - padding, 
            text_position[1] - padding,
            text_position[0] + text_width + padding,
            text_position[1] + text_height + padding
        ],
        fill=bg_color
    )
    
    # Metni Ã§iz
    if hasattr(overlay_draw, 'text'):
        overlay_draw.text(text_position, text, font=font, fill=color)
    
    # Orijinal gÃ¶rÃ¼ntÃ¼ye arka planÄ± ve metni birleÅŸtir
    img = Image.alpha_composite(img.convert('RGBA'), overlay)
    
    return img.convert('RGB')

def add_logo_overlay(image, logo_image, position="bottom-right", size_percent=15, padding=10,
                    opacity=0.8):
    """
    GÃ¶rÃ¼ntÃ¼ye logo ekler
    
    Args:
        image: PIL gÃ¶rÃ¼ntÃ¼sÃ¼
        logo_image: Logo PIL gÃ¶rÃ¼ntÃ¼sÃ¼
        position: Logo konumu
        size_percent: GÃ¶rÃ¼ntÃ¼ boyutunun yÃ¼zdesi olarak logo boyutu
        padding: Logo kenarlarÄ± ile gÃ¶rÃ¼ntÃ¼ kenarÄ± arasÄ±ndaki dolgu
        opacity: Logo opaklÄ±ÄŸÄ± (0-1)
        
    Returns:
        Logo eklenmiÅŸ PIL gÃ¶rÃ¼ntÃ¼sÃ¼
    """
    # Orijinal gÃ¶rÃ¼ntÃ¼ ve logo boyutlarÄ±
    img = image.copy()
    width, height = img.size
    logo = logo_image.copy()
    
    # Logo boyutunu ayarla
    logo_width = int(width * size_percent / 100)
    logo_height = int(logo.height * logo_width / logo.width)
    logo = logo.resize((logo_width, logo_height), Image.LANCZOS)
    
    # Logo konumunu belirle
    if position == "top-left":
        logo_position = (padding, padding)
    elif position == "top-right":
        logo_position = (width - logo_width - padding, padding)
    elif position == "bottom-left":
        logo_position = (padding, height - logo_height - padding)
    elif position == "bottom-right":
        logo_position = (width - logo_width - padding, height - logo_height - padding)
    elif position == "center":
        logo_position = ((width - logo_width) / 2, (height - logo_height) / 2)
    else:
        logo_position = (width - logo_width - padding, height - logo_height - padding)
    
    # Logo opaklÄ±ÄŸÄ±nÄ± ayarla
    if logo.mode != 'RGBA':
        logo = logo.convert('RGBA')
    
    # RGBA kanallarÄ±nÄ± ayÄ±r
    r, g, b, a = logo.split()
    
    # Alfa kanalÄ±nÄ± opaklÄ±k ile Ã§arp
    a = a.point(lambda x: x * opacity)
    
    # KanallarÄ± yeniden birleÅŸtir
    logo = Image.merge('RGBA', (r, g, b, a))
    
    # Orijinal gÃ¶rÃ¼ntÃ¼ye logoyu ekle
    img_with_logo = img.copy().convert('RGBA')
    img_with_logo.paste(logo, (int(logo_position[0]), int(logo_position[1])), logo)
    
    return img_with_logo.convert('RGB')

def apply_overlays_to_video_frames(frames, text=None, text_options=None, logo=None, logo_options=None):
    """
    Video karelerine metin ve/veya logo ekler
    
    Args:
        frames: Ä°ÅŸlenecek video kareleri listesi
        text: Eklenecek metin (None ise metin eklenmez)
        text_options: Metin ekleme seÃ§enekleri sÃ¶zlÃ¼ÄŸÃ¼
        logo: Logo gÃ¶rÃ¼ntÃ¼sÃ¼ (None ise logo eklenmez)
        logo_options: Logo ekleme seÃ§enekleri sÃ¶zlÃ¼ÄŸÃ¼
        
    Returns:
        DÃ¼zenlenmiÅŸ video kareleri listesi
    """
    if text is None and logo is None:
        return frames
        
    processed_frames = []
    
    for frame in frames:
        # NumPy dizisini PIL gÃ¶rÃ¼ntÃ¼sÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼r
        pil_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        
        # Metin ekle
        if text is not None:
            text_opts = text_options or {}
            pil_frame = add_text_overlay(pil_frame, text, **text_opts)
        
        # Logo ekle
        if logo is not None:
            logo_opts = logo_options or {}
            pil_frame = add_logo_overlay(pil_frame, logo, **logo_opts)
        
        # PIL gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ NumPy dizisine geri dÃ¶nÃ¼ÅŸtÃ¼r
        processed_frame = cv2.cvtColor(np.array(pil_frame), cv2.COLOR_RGB2BGR)
        processed_frames.append(processed_frame)
    
    return processed_frames
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/combined_code.py
-e 

# File: /home/jobbe/Desktop/Projects/emlak-web/app.py
# IMPORTANT: This must be the first Streamlit command in the app
import streamlit as st

st.set_page_config(
    page_title="Sanal Drone Emlak Video OluÅŸturucu",
    layout="wide",
    initial_sidebar_state="expanded",
)

"""Emlak Video OluÅŸturucu - Ana Uygulama"""

from PIL import Image
import gc
import os
import folium
import time
import sys
from pathlib import Path

# Add the project root to path to fix imports
project_root = Path(__file__).parent
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

# Import local modules
from config.config import (
    initialize_session_state,
    VOICE_OPTIONS,
    DEFAULT_VOICE,
    VIDEO_DIR,
)
from modules.text.text_generation import generate_property_description
from modules.audio.audio_generation import generate_audio_from_text, get_audio_duration
from modules.image.image_processing import (
    fetch_satellite_image,
    fetch_street_view_image,
    draw_property_border,
    enhance_image,
)
from modules.video.video_generation import generate_video
from modules.geo.geo_utils import get_coordinates_from_address, get_nearby_places
from utils.utils import calculate_distance, cleanup_temp_files
from streamlit_folium import st_folium

# Yeni durum yÃ¶netimi ve arka plan gÃ¶revleri modÃ¼llerini iÃ§e aktar
from utils.state_manager import StateManager
from utils.background_tasks import BackgroundTaskManager, generate_video_in_background

# Add missing imports
import cv2
import numpy as np
import tempfile

# Import overlay and music functions
from modules.video.overlay_tools import add_text_overlay, add_logo_overlay
from modules.audio.music_library import get_music_options, mix_audio, download_music
from utils.cache_utils import cached_data, clear_cache, clear_disk_cache

# Add at the top with other imports:
from utils.system_check import display_system_info
from modules.video.preview_utils import show_video_preview

# Fix the rerun function usage
from streamlit import runtime
from streamlit.runtime.scriptrunner import get_script_run_ctx

# Add at the top with other imports
import os
from pathlib import Path

# Add after other constants
TEMP_DIR = os.path.join(os.path.dirname(__file__), 'temp')
STORAGE_DIR = os.path.join(os.path.dirname(__file__), 'storage')

# Create directories if they don't exist
os.makedirs(TEMP_DIR, exist_ok=True)
os.makedirs(STORAGE_DIR, exist_ok=True)

def safe_rerun():
    """Safely rerun the app"""
    try:
        st.rerun()
    except:
        # Fallback for very old Streamlit versions
        try:
            st.experimental_rerun()
        except:
            st.warning("Could not rerun the app. Please refresh the page manually.")


# Ana uygulama sÄ±nÄ±fÄ±
class EmlakVideoApp:
    def __init__(self):
        # Uygulama baÅŸlangÄ±Ã§ ayarlarÄ±
        self.initialize_app()

        # Durum yÃ¶neticisi ve arka plan gÃ¶rev yÃ¶neticisi oluÅŸtur
        self.state_manager = StateManager()
        self.task_manager = BackgroundTaskManager()

    def initialize_app(self):
        """UygulamayÄ± baÅŸlat ve gerekli dizinleri oluÅŸtur"""
        initialize_session_state()
        # st.set_page_config was moved to the top of the file

    def run(self):
        """Ana uygulama akÄ±ÅŸÄ±nÄ± Ã§alÄ±ÅŸtÄ±r"""
        # BaÅŸlÄ±k ve sidebar'Ä± ayarla
        self.setup_header()
        self.setup_sidebar()

        # Emlak adres giriÅŸi (ana ekranda her zaman gÃ¶rÃ¼nÃ¼r)
        self.setup_address_input()

        # Arka plan gÃ¶revlerini kontrol et ve gÃ¶rÃ¼ntÃ¼le
        self.check_background_tasks()

        # Ana sekmeleri oluÅŸtur
        if "current_view" not in st.session_state:
            st.session_state["current_view"] = "tabs"  # VarsayÄ±lan gÃ¶rÃ¼nÃ¼m: tabs

        if st.session_state["current_view"] == "tabs":
            self.show_tabbed_interface()
        else:
            # Alternatif olarak wizard arayÃ¼zÃ¼ eklenebilir
            self.show_wizard_interface()

    def setup_header(self):
        """Uygulama baÅŸlÄ±ÄŸÄ±nÄ± ve Ã¼st bilgiyi ayarla"""
        st.title("ğŸ  Sanal Drone Emlak Video OluÅŸturucu")

        # Proje yÃ¶netimi butonlarÄ±
        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("ğŸ’¾ Projeyi Kaydet"):
                self.save_project()

        with col2:
            if st.button("ğŸ“‚ Projeyi AÃ§"):
                self.load_project()

        with col3:
            if st.button("ğŸ§¹ Ã–nbelleÄŸi Temizle"):
                self.clear_cache()

    def setup_sidebar(self):
        """Kenar Ã§ubuÄŸu ayarlarÄ±nÄ± oluÅŸtur"""
        with st.sidebar:
            st.header("Video AyarlarÄ±")

            # GÃ¶rÃ¼nÃ¼m seÃ§imi
            st.session_state["current_view"] = st.radio(
                "ArayÃ¼z GÃ¶rÃ¼nÃ¼mÃ¼",
                options=["tabs"],
                format_func=lambda x: "Sekmeli GÃ¶rÃ¼nÃ¼m"
                
            )

            # Video ayarlarÄ±
            st.session_state["fps"] = st.slider(
                "Kare HÄ±zÄ± (FPS)", 15, 60, 30, help="Saniyedeki kare sayÄ±sÄ±"
            )
            st.session_state["video_quality"] = st.radio(
                "Video Kalitesi",
                ["normal", "high"],
                format_func=lambda x: "Normal (720p)"
                if x == "normal"
                else "YÃ¼ksek (1080p)",
            )
            st.session_state["transition_type"] = st.selectbox(
                "GeÃ§iÅŸ Efekti", ["YakÄ±nlaÅŸma", "KaydÄ±rma", "YakÄ±nlaÅŸma ve KaydÄ±rma"]
            )

            # GÃ¶rÃ¼ntÃ¼ iyileÅŸtirme ayarlarÄ±
            st.session_state["enhance_colors"] = st.checkbox(
                "GÃ¶rÃ¼ntÃ¼ Renklerini GeliÅŸtir", value=True
            )
            st.session_state["color_boost"] = st.slider("Renk CanlÄ±lÄ±ÄŸÄ±", 1.0, 2.5, 1.5)

            # Åablonlar menÃ¼sÃ¼
            self.show_templates()

    def show_templates(self):
        """HazÄ±r ÅŸablonlarÄ± gÃ¶ster ve uygula"""
        st.subheader("ğŸ“‹ HazÄ±r Åablonlar")

        templates = {
            "LÃ¼ks Konut": {
                "transition_type": "YakÄ±nlaÅŸma ve KaydÄ±rma",
                "fps": 30,
                "video_quality": "high",
                "color_boost": 1.8,
                "description": "YÃ¼ksek kaliteli, akÄ±cÄ± geÃ§iÅŸlerle lÃ¼ks konut videolarÄ± iÃ§in ideal ayarlar.",
            },
            "Ticari Emlak": {
                "transition_type": "KaydÄ±rma",
                "fps": 24,
                "video_quality": "high",
                "color_boost": 1.3,
                "description": "Ticari mÃ¼lkler iÃ§in profesyonel gÃ¶rÃ¼nÃ¼mlÃ¼, yÃ¼ksek kalitede sunumlar.",
            },
            "Ekonomik Paket": {
                "transition_type": "YakÄ±nlaÅŸma",
                "fps": 24,
                "video_quality": "normal",
                "color_boost": 1.5,
                "description": "HÄ±zlÄ± ve verimli oluÅŸturma iÃ§in optimize edilmiÅŸ temel ayarlar.",
            },
            "Arsa/Arazi": {
                "transition_type": "YakÄ±nlaÅŸma ve KaydÄ±rma",
                "fps": 30,
                "video_quality": "high",
                "color_boost": 2.0,
                "description": "Arsa ve arazi gÃ¶rÃ¼ntÃ¼lerini vurgulamak iÃ§in uyarlanmÄ±ÅŸ, canlÄ± renkli ayarlar.",
            },
            "Deniz ManzaralÄ±": {
                "transition_type": "KaydÄ±rma",
                "fps": 30,
                "video_quality": "high",
                "color_boost": 1.7,
                "description": "Deniz ve gÃ¶l manzaralarÄ±nÄ± Ã¶ne Ã§Ä±karan, mavi tonlarÄ± vurgulayan ayarlar.",
            },
        }

        selected_template = st.selectbox(
            "Åablon SeÃ§:", ["Ã–zel"] + list(templates.keys())
        )

        if selected_template != "Ã–zel":
            # SeÃ§ilen ÅŸablonun aÃ§Ä±klamasÄ±nÄ± gÃ¶ster
            st.info(templates[selected_template]["description"])

            if st.button(f"'{selected_template}' Åablonunu Uygula"):
                # SeÃ§ilen ÅŸablonu uygula
                template = templates[selected_template]
                for key, value in template.items():
                    if key != "description":  # AÃ§Ä±klama hariÃ§ diÄŸer Ã¶zellikleri ayarla
                        st.session_state[key] = value
                st.success(f"'{selected_template}' ÅŸablonu uygulandÄ±!")
                safe_rerun()

    def setup_address_input(self):
        """Emlak adres giriÅŸi alanÄ±nÄ± oluÅŸtur"""
        st.header("ğŸ“ Emlak Konumu")
        address = st.text_input(
            "Emlak adresi:",
            placeholder="Ã–rnek: AtatÃ¼rk Mah. Cumhuriyet Cad. No:123, Ä°stanbul",
        )

        if address:
            # Konum verilerini al
            with st.spinner("Adres bilgileri alÄ±nÄ±yor..."):
                lat, lng, formatted_address = get_coordinates_from_address(address)
                if lat and lng:
                    st.session_state["property_location"] = {
                        "lat": lat,
                        "lng": lng,
                        "formatted_address": formatted_address,
                    }
                    st.success(f"Konum bulundu: {formatted_address}")

                    # Harita oluÅŸtur ve gÃ¶ster
                    m = folium.Map(location=[lat, lng], zoom_start=15)
                    folium.Marker([lat, lng], tooltip="Emlak Konumu").add_to(m)
                    st_folium(m, width=800, height=300)
                else:
                    st.error("Adres bulunamadÄ±. LÃ¼tfen geÃ§erli bir adres girin.")

    def check_background_tasks(self):
        """Devam eden arka plan gÃ¶revlerini kontrol et ve gÃ¶rÃ¼ntÃ¼le"""
        # TamamlanmÄ±ÅŸ eski gÃ¶revleri temizle
        self.task_manager.cleanup_completed_tasks(max_age_seconds=1800)  # 30 dakika

        # Video oluÅŸturma gÃ¶revi varsa kontrol et
        if "video_task_id" in st.session_state:
            task_id = st.session_state["video_task_id"]
            task_status = self.task_manager.get_task_status(task_id)

            if task_status:
                # Devam eden gÃ¶rev varsa, durumunu gÃ¶ster
                if task_status["status"] in [
                    "starting",
                    "running",
                    "preparing",
                    "processing_images",
                    "generating_video",
                ]:
                    st.header("ğŸ¬ Video OluÅŸturuluyor")
                    st.info(f"Video oluÅŸturma iÅŸlemi devam ediyor...")

                    # Calculate stage name in Turkish
                    stage_name = {
                        "starting": "BaÅŸlatÄ±lÄ±yor",
                        "running": "Ã‡alÄ±ÅŸÄ±yor",
                        "preparing": "HazÄ±rlanÄ±yor",
                        "processing_images": "GÃ¶rÃ¼ntÃ¼ler Ä°ÅŸleniyor",
                        "generating_video": "Video OluÅŸturuluyor",
                    }.get(task_status["status"], task_status["status"])

                    col1, col2 = st.columns([3, 1])

                    with col1:
                        progress = task_status["progress"] / 100.0
                        progress_bar = st.progress(progress)
                        st.caption(f"Ä°ÅŸlem: {stage_name}")

                    with col2:
                        st.metric("TamamlandÄ±", f"%{int(progress * 100)}")

                    if "message" in task_status and task_status["message"]:
                        st.caption(f"Detay: {task_status['message']}")

                    # Her 2 saniyede bir yenile
                    time.sleep(2)
                    safe_rerun()

                # Tamamlanan gÃ¶rev varsa, sonucu gÃ¶ster
                elif task_status["status"] == "completed":
                    video_path = task_status["result"]
                    if video_path and os.path.exists(video_path):
                        st.header("ğŸ‰ Video HazÄ±r!")
                        st.success("Video baÅŸarÄ±yla oluÅŸturuldu!")

                        # Video dosya bilgileri
                        video_size_mb = os.path.getsize(video_path) / (1024 * 1024)
                        video_info = f"Video boyutu: {video_size_mb:.1f} MB"
                        st.info(video_info)

                        # Videoyu gÃ¶ster
                        st.video(video_path)

                        # Ä°ndirme butonu
                        with open(video_path, "rb") as file:
                            st.download_button(
                                "ğŸ“¥ Videoyu Ä°ndir",
                                data=file,
                                file_name="emlak_videosu.mp4",
                                mime="video/mp4",
                                help="Videoyu cihazÄ±nÄ±za kaydedin",
                            )

                    # Ä°ÅŸlem tamamlandÄ±ÄŸÄ± iÃ§in gÃ¶rev ID'sini temizle
                    del st.session_state["video_task_id"]

                # Hata durumunda gÃ¶ster
                elif task_status["status"] == "failed":
                    st.header("âŒ Video OluÅŸturma HatasÄ±")
                    st.error(
                        f"Video oluÅŸturulurken bir hata meydana geldi: {task_status['error']}"
                    )

                    # Hata detayÄ±
                    with st.expander("Hata DetaylarÄ±"):
                        if "error_details" in task_status:
                            st.code(task_status["error_details"])
                        else:
                            st.write("DetaylÄ± hata bilgisi mevcut deÄŸil.")

                    # Yeniden deneme butonu
                    if st.button(
                        "ğŸ”„ Yeniden Dene", help="Video oluÅŸturmayÄ± tekrar deneyin"
                    ):
                        del st.session_state["video_task_id"]
                        safe_rerun()

                    del st.session_state["video_task_id"]

    def save_project(self):
        """Projeyi kaydet diyalog kutusu"""
        with st.form(key="save_project_form"):
            project_name = st.text_input("Proje adÄ±:", max_chars=50)
            overwrite = st.checkbox("AynÄ± isimli proje varsa Ã¼zerine yaz")

            submit_button = st.form_submit_button(label="Kaydet")

            if submit_button:
                if not project_name:
                    st.error("Proje adÄ± boÅŸ olamaz!")
                    return

                # Proje verilerini al
                project_data = self.state_manager.get_project_data()

                # Projeyi kaydet
                success = self.state_manager.save_project(
                    project_name, project_data, overwrite
                )

                if success:
                    st.success(f"Proje '{project_name}' baÅŸarÄ±yla kaydedildi!")
                else:
                    st.error(
                        f"Proje '{project_name}' kaydedilemedi. AynÄ± isimli bir proje zaten mevcut."
                    )

    def load_project(self):
        """Projeyi aÃ§ diyalog kutusu"""
        with st.form(key="load_project_form"):
            project_name = st.text_input("AÃ§Ä±lacak proje adÄ±:", max_chars=50)

            submit_button = st.form_submit_button(label="AÃ§")

            if submit_button:
                if not project_name:
                    st.error("Proje adÄ± boÅŸ olamaz!")
                    return

                # Projeyi yÃ¼kle
                project_data = self.state_manager.load_project(project_name)

                if project_data:
                    self.state_manager.set_project_data(project_data)
                    st.success(f"Proje '{project_name}' baÅŸarÄ±yla yÃ¼klendi!")
                    safe_rerun()
                else:
                    st.error(f"Proje '{project_name}' bulunamadÄ±.")

    def clear_cache(self):
        """Ã–nbelleÄŸi temizle"""
        from utils.cache_utils import clear_cache as cc

        cc()  # Streamlit Ã¶nbelleÄŸi temizler

        # Disk Ã¶nbelleÄŸini temizle
        from utils.cache_utils import clear_disk_cache

        clear_disk_cache()

        # GeÃ§ici dosyalarÄ± temizle
        cleanup_temp_files(None)
        st.success("Ã–nbellek baÅŸarÄ±yla temizlendi!")

    def show_tabbed_interface(self):
        """Sekme tabanlÄ± arayÃ¼zÃ¼ gÃ¶ster"""
        tabs = st.tabs(
            [
                "1. Emlak Bilgileri",
                "2. Sesli AnlatÄ±m",
                "3. GÃ¶rÃ¼ntÃ¼ler",
                "4. Video OluÅŸtur",
            ]
        )

        # Her sekme iÃ§in ilgili controller'Ä± Ã§aÄŸÄ±r
        with tabs[0]:
            property_controller = PropertyController()
            property_controller.show_property_form()

        with tabs[1]:
            audio_controller = AudioController()
            audio_controller.show_audio_generation()

        with tabs[2]:
            image_controller = ImageController()
            image_controller.show_image_collection()

        with tabs[3]:
            video_controller = VideoController(self.task_manager)
            video_controller.show_video_generation()

    def show_wizard_interface(self):
        """AdÄ±m adÄ±m sihirbaz arayÃ¼zÃ¼nÃ¼ gÃ¶ster (ileride uygulanabilir)"""
        wizard = PropertyVideoWizard()
        wizard.show()


# Controller sÄ±nÄ±flarÄ± - Her biri uygulamanÄ±n bir yÃ¶nÃ¼nÃ¼ kontrol eder
class PropertyController:
    """Emlak detaylarÄ± ve metin oluÅŸturma iÃ§in controller"""

    def show_property_form(self):
        st.header("Emlak Bilgileri")
        if "property_location" not in st.session_state:
            st.warning("LÃ¼tfen Ã¶nce emlak adresini girin!")
            return

        col1, col2 = st.columns(2)

        with col1:
            property_type = st.selectbox(
                "Emlak Tipi:",
                ["Daire", "Villa", "MÃ¼stakil Ev", "Arsa", "Ticari", "DiÄŸer"],
            )
            rooms = st.number_input("Oda SayÄ±sÄ±:", min_value=0, max_value=20, value=3)
            bathrooms = st.number_input(
                "Banyo SayÄ±sÄ±:", min_value=0, max_value=10, value=1
            )

        with col2:
            area = st.number_input("Metrekare:", min_value=1, value=120)
            price = st.number_input("Fiyat (TL):", min_value=0, value=1500000)
            year_built = st.number_input(
                "YapÄ±m YÄ±lÄ±:", min_value=1900, max_value=2025, value=2010
            )

        special_features = st.text_area(
            "Ã–zel Ã–zellikler:",
            placeholder="Ã–rnek: Deniz manzarasÄ±, yÃ¼zme havuzu, gÃ¼venlik, otopark vb.",
            height=100,
        )

        # Ã‡evre bilgilerini getir
        nearby_places = self._get_nearby_info()

        # Metin oluÅŸtur butonu
        if st.button("Emlak Metni OluÅŸtur", type="primary"):
            self._generate_description(
                property_type,
                rooms,
                bathrooms,
                area,
                price,
                year_built,
                special_features,
                nearby_places,
            )

    def _get_nearby_info(self):
        """YakÄ±n Ã§evre bilgilerini getir"""
        include_nearby = st.checkbox("YakÄ±n Ã‡evre Bilgilerini Ekle", value=True)
        nearby_places = None

        if include_nearby:
            nearby_radius = st.slider(
                "AraÅŸtÄ±rma YarÄ±Ã§apÄ± (metre)", 500, 2000, 1000, 100
            )
            with st.spinner("YakÄ±n Ã§evre analizi yapÄ±lÄ±yor..."):
                nearby_places = get_nearby_places(
                    st.session_state["property_location"]["lat"],
                    st.session_state["property_location"]["lng"],
                    radius=nearby_radius,
                    types=[
                        "school,hospital,shopping_mall,park,restaurant,subway_station,bus_station"
                    ],
                )

                if nearby_places:
                    with st.expander("YakÄ±ndaki Ã–nemli Noktalar"):
                        for place in sorted(nearby_places, key=lambda x: x["distance"]):
                            st.write(
                                f"ğŸ¢ **{place['name']}** ({place['type'].replace('_', ' ')}) - {place['distance']}m"
                            )

        return nearby_places

    def _generate_description(
        self,
        property_type,
        rooms,
        bathrooms,
        area,
        price,
        year_built,
        special_features,
        nearby_places,
    ):
        """Emlak aÃ§Ä±klama metni oluÅŸtur"""
        with st.spinner("Metin oluÅŸturuluyor..."):
            property_data = {
                "address": st.session_state["property_location"]["formatted_address"],
                "property_type": property_type,
                "rooms": rooms,
                "bathrooms": bathrooms,
                "area": area,
                "price": price,
                "year_built": year_built,
                "special_features": special_features,
                "description": "",
            }

            generated_text = generate_property_description(
                property_data, nearby_places if nearby_places else None
            )

            if generated_text:
                st.session_state["property_text"] = generated_text
                st.success("Metin baÅŸarÄ±yla oluÅŸturuldu!")
                st.markdown("### OluÅŸturulan Metin:")
                st.write(generated_text)

                edited_text = st.text_area(
                    "Metni DÃ¼zenleyin (isteÄŸe baÄŸlÄ±):", value=generated_text, height=200
                )

                if edited_text != generated_text:
                    st.session_state["property_text"] = edited_text


class AudioController:
    """Ses oluÅŸturma ve yÃ¶netimi iÃ§in controller"""

    def show_audio_generation(self):
        st.header("Sesli AnlatÄ±m OluÅŸtur")

        if "property_text" not in st.session_state:
            st.warning("LÃ¼tfen Ã¶nce emlak bilgilerini girin!")
            return

        st.write(st.session_state["property_text"])

        # Ses seÃ§enekleri eklenebilir
        voice_id = st.selectbox(
            "Ses SeÃ§in:",
            options=list(VOICE_OPTIONS.keys()),
            format_func=lambda x: VOICE_OPTIONS[x],
            index=list(VOICE_OPTIONS.keys()).index(DEFAULT_VOICE),
        )
        st.session_state["voice_id"] = voice_id

        if st.button("Sesli AnlatÄ±m OluÅŸtur"):
            self._generate_audio()

    def _generate_audio(self):
        """Metinden ses oluÅŸtur"""
        audio_path = generate_audio_from_text(
            st.session_state["property_text"],
            st.session_state.get("voice_id", DEFAULT_VOICE),
        )

        if audio_path:
            st.session_state["audio_path"] = audio_path
            st.session_state["audio_duration"] = get_audio_duration(audio_path)
            st.success("Sesli anlatÄ±m baÅŸarÄ±yla oluÅŸturuldu!")
            st.audio(audio_path)


class ImageController:
    """GÃ¶rÃ¼ntÃ¼ toplama ve iÅŸleme iÃ§in controller"""

    def show_image_collection(self):
        st.header("GÃ¶rÃ¼ntÃ¼leri Topla")

        if "property_location" not in st.session_state:
            st.warning("LÃ¼tfen Ã¶nce emlak adresini girin!")
            return

        col1, col2 = st.columns(2)

        with col1:
            self._show_map_images()

        with col2:
            self._show_custom_images()

    def _show_map_images(self):
        """Harita ve uydu gÃ¶rÃ¼ntÃ¼lerini gÃ¶ster"""
        st.subheader("Harita GÃ¶rÃ¼ntÃ¼leri")

        zoom_level = st.slider("YakÄ±nlaÅŸtÄ±rma Seviyesi", 15, 20, 18)
        map_type = st.selectbox(
            "Harita Tipi",
            ["satellite", "hybrid", "roadmap"],
            format_func=lambda x: {
                "satellite": "Uydu",
                "hybrid": "Hibrit",
                "roadmap": "Yol HaritasÄ±",
            }[x],
        )

        if st.button("Harita GÃ¶rÃ¼ntÃ¼lerini Getir"):
            self._fetch_map_images(zoom_level, map_type)

        # Emlak sÄ±nÄ±rÄ± Ã§izme Ã¶zelliÄŸi
        if (
            "maps_images" in st.session_state
            and len(st.session_state["maps_images"]) > 0
        ):
            self._show_border_drawing()

    def _fetch_map_images(self, zoom_level, map_type):
        """Harita gÃ¶rÃ¼ntÃ¼lerini getir"""
        with st.spinner("GÃ¶rÃ¼ntÃ¼ler alÄ±nÄ±yor..."):
            lat = st.session_state["property_location"]["lat"]
            lng = st.session_state["property_location"]["lng"]

            # Uydu gÃ¶rÃ¼ntÃ¼lerini al
            satellite_images = []
            progress_bar = st.progress(0)

            main_img = fetch_satellite_image(
                lat=lat, lng=lng, zoom=zoom_level, maptype=map_type
            )
            if main_img:
                # Renk iyileÅŸtirmeyi uygula
                if st.session_state["enhance_colors"]:
                    main_img = enhance_image(
                        main_img, boost_factor=st.session_state["color_boost"]
                    )
                satellite_images.append(main_img)

                # FarklÄ± zoom seviyelerindeki gÃ¶rÃ¼ntÃ¼ler
                zoom_levels = [zoom_level - 1, zoom_level - 2, zoom_level + 1]
                for i, zoom in enumerate(zoom_levels):
                    img = fetch_satellite_image(
                        lat=lat, lng=lng, zoom=zoom, maptype=map_type
                    )
                    if img:
                        # Renk iyileÅŸtirmeyi uygula
                        if st.session_state["enhance_colors"]:
                            img = enhance_image(
                                img, boost_factor=st.session_state["color_boost"]
                            )
                        satellite_images.append(img)
                    progress_bar.progress((i + 1) / len(zoom_levels))

            # Sokak gÃ¶rÃ¼ntÃ¼lerini al
            headings = [0, 90, 180, 270]
            street_view_images = []

            for heading in headings:
                img = fetch_street_view_image(lat=lat, lng=lng, heading=heading)
                if img:
                    street_view_images.append(img)

            # TÃ¼m gÃ¶rÃ¼ntÃ¼leri birleÅŸtir
            all_images = satellite_images + street_view_images
            if all_images:
                st.session_state["maps_images"] = all_images
                st.success(f"{len(all_images)} gÃ¶rÃ¼ntÃ¼ baÅŸarÄ±yla alÄ±ndÄ±!")

                # GÃ¶rÃ¼ntÃ¼leri grid iÃ§inde gÃ¶ster
                cols = st.columns(3)
                for idx, img in enumerate(all_images):
                    with cols[idx % 3]:
                        st.image(img, caption=f"GÃ¶rÃ¼ntÃ¼ {idx + 1}")

    def _show_border_drawing(self):
        """Emlak sÄ±nÄ±rÄ± Ã§izme arayÃ¼zÃ¼nÃ¼ gÃ¶ster"""
        st.subheader("Emlak SÄ±nÄ±rÄ± Ã‡izme")
        st.info(
            "Uydu gÃ¶rÃ¼ntÃ¼sÃ¼ Ã¼zerinde emlak sÄ±nÄ±rÄ±nÄ± belirlemek iÃ§in aÅŸaÄŸÄ±daki ayarlarÄ± kullanÄ±n."
        )

        # SÄ±nÄ±r Ã§izilecek gÃ¶rÃ¼ntÃ¼yÃ¼ seÃ§
        image_options = [
            f"GÃ¶rÃ¼ntÃ¼ {i + 1}" for i in range(len(st.session_state["maps_images"]))
        ]
        selected_img_idx = st.selectbox(
            "SÄ±nÄ±r Ã§izilecek gÃ¶rÃ¼ntÃ¼yÃ¼ seÃ§in:",
            range(len(image_options)),
            format_func=lambda i: image_options[i],
        )

        selected_image = st.session_state["maps_images"][selected_img_idx]

        # SeÃ§ili gÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶ster
        st.image(selected_image, caption="SeÃ§ilen GÃ¶rÃ¼ntÃ¼", use_container_width=True)

        # SÄ±nÄ±r ayarlarÄ±
        col_color, col_width, col_ratio = st.columns(3)

        with col_color:
            border_colors = {
                "#FF0000": "KÄ±rmÄ±zÄ±",
                "#00FF00": "YeÅŸil",
                "#0000FF": "Mavi",
                "#FFFF00": "SarÄ±",
                "#FF00FF": "Mor",
                "#00FFFF": "Turkuaz",
            }
            color_key = st.selectbox(
                "SÄ±nÄ±r Rengi:",
                list(border_colors.keys()),
                format_func=lambda x: border_colors[x],
            )

        with col_width:
            border_width = st.slider("SÄ±nÄ±r KalÄ±nlÄ±ÄŸÄ±:", 1, 10, 3)

        with col_ratio:
            border_ratio = st.slider(
                "SÄ±nÄ±r Konumu:",
                0.05,
                0.45,
                0.2,
                help="0.5'e yakÄ±n deÄŸerler sÄ±nÄ±rÄ± merkeze, 0'a yakÄ±n deÄŸerler kenarlara yaklaÅŸtÄ±rÄ±r",
            )

        # SÄ±nÄ±rÄ± Ã§iz butonu
        if st.button("SÄ±nÄ±rÄ± Ã‡iz", type="primary"):
            with st.spinner("SÄ±nÄ±r Ã§iziliyor..."):
                bordered_image = draw_property_border(
                    selected_image, color_key, border_width, border_ratio
                )

                # Session state'te sakla
                st.session_state["bordered_property_image"] = bordered_image

                # Sonucu gÃ¶ster
                st.success("SÄ±nÄ±r baÅŸarÄ±yla Ã§izildi!")
                st.image(
                    bordered_image,
                    caption="SÄ±nÄ±rlÄ± Emlak GÃ¶rÃ¼ntÃ¼sÃ¼",
                    use_container_width=True,
                )

                # Videoya dahil etme seÃ§eneÄŸi
                include_in_video = st.checkbox(
                    "Bu gÃ¶rÃ¼ntÃ¼yÃ¼ videoya dahil et", value=True
                )
                if include_in_video:
                    # Orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ sÄ±nÄ±rlÄ± olanla deÄŸiÅŸtir veya yeni gÃ¶rÃ¼ntÃ¼ olarak ekle
                    new_maps_images = st.session_state["maps_images"].copy()
                    new_maps_images.insert(
                        0, bordered_image
                    )  # SÄ±nÄ±rlÄ± gÃ¶rÃ¼ntÃ¼yÃ¼ ilk sÄ±raya ekle
                    st.session_state["maps_images"] = new_maps_images
                    st.info("SÄ±nÄ±rlÄ± gÃ¶rÃ¼ntÃ¼ video gÃ¶rsellerine eklendi!")

    def _show_custom_images(self):
        """KullanÄ±cÄ± tarafÄ±ndan yÃ¼klenen Ã¶zel gÃ¶rÃ¼ntÃ¼leri gÃ¶ster"""
        st.subheader("Ã–zel GÃ¶rÃ¼ntÃ¼ler")
        uploaded_files = st.file_uploader(
            "Kendi gÃ¶rsellerinizi ekleyin:",
            type=["jpg", "jpeg", "png"],
            accept_multiple_files=True,
            help="En fazla 5 gÃ¶rsel ekleyebilirsiniz.",
        )

        if uploaded_files:
            user_images = []
            for file in uploaded_files[:5]:
                img = Image.open(file)
                user_images.append(img)

            st.session_state["user_images"] = user_images
            st.success(f"{len(user_images)} Ã¶zel gÃ¶rsel eklendi!")

            for idx, img in enumerate(user_images):
                st.image(
                    img, caption=f"Ã–zel GÃ¶rsel {idx + 1}", use_container_width=True
                )


class VideoController:
    """Video oluÅŸturma ve iÅŸleme iÃ§in controller"""

    def __init__(self, task_manager):
        self.task_manager = task_manager

    def _check_requirements(self):
        """
        Videoyu oluÅŸturmak iÃ§in gerekli tÃ¼m bileÅŸenlerin mevcut olup olmadÄ±ÄŸÄ±nÄ± kontrol eder

        Returns:
            tuple: (requirements_met, missing_components_list)
        """
        missing_components = []

        # Ses dosyasÄ± kontrol
        if "audio_path" not in st.session_state:
            missing_components.append("Sesli anlatÄ±m")

        # GÃ¶rÃ¼ntÃ¼leri kontrol et
        if not ("maps_images" in st.session_state or "user_images" in st.session_state):
            missing_components.append("GÃ¶rÃ¼ntÃ¼ler")

        # En az bir gÃ¶rÃ¼ntÃ¼ var mÄ±?
        images_count = 0
        if "maps_images" in st.session_state:
            images_count += len(st.session_state["maps_images"])
        if "user_images" in st.session_state:
            images_count += len(st.session_state["user_images"])

        if images_count == 0:
            missing_components.append("En az bir gÃ¶rÃ¼ntÃ¼")

        # Gerekli tÃ¼m bileÅŸenler mevcut mu?
        requirements_met = len(missing_components) == 0

        return requirements_met, missing_components

    def show_video_generation(self):
        st.header("Video OluÅŸtur")

        # Gereksinimleri kontrol et
        requirements_met, missing_components = self._check_requirements()

        if not requirements_met:
            st.warning(f"Eksik bileÅŸenler: {', '.join(missing_components)}")
            return

        st.success("TÃ¼m bileÅŸenler hazÄ±r! Videoyu oluÅŸturabilirsiniz.")

        # Display system information (new)
        display_system_info()

        # Video geliÅŸmiÅŸ ayarlarÄ± iÃ§in sekmeler
        tabs = st.tabs(["Temel Ayarlar", "Arkaplan MÃ¼ziÄŸi", "Metin/Logo Ekle", "GeliÅŸmiÅŸ Efektler"])

        with tabs[0]:
            # Mevcut video ayarlarÄ±
            st.subheader("Video AyarlarÄ±")
            resolution_option = st.selectbox(
                "Video Ã‡Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼",
                ["720p (HD)", "1080p (Full HD)"],
                index=0
                if st.session_state.get("video_quality", "normal") == "normal"
                else 1,
            )
            st.session_state["video_quality"] = (
                "normal" if "720p" in resolution_option else "high"
            )

        with tabs[1]:
            self._show_music_options()

        with tabs[2]:
            self._show_overlay_options()
            
        with tabs[3]:
            self._show_advanced_effects()

        # After all images are loaded but before video generation
        # Add a preview section (new)
        all_images = []
        if "maps_images" in st.session_state:
            all_images.extend(st.session_state["maps_images"][:8])
        if "user_images" in st.session_state:
            all_images.extend(st.session_state["user_images"][:5])

        if all_images:
            show_video_preview(all_images, st.session_state.get("audio_path", None))

        # Your existing video generation button
        if st.button("Video OluÅŸtur", type="primary"):
            self._generate_video()

    def _show_music_options(self):
        """Arkaplan mÃ¼ziÄŸi seÃ§eneklerini gÃ¶ster"""
        st.subheader("ğŸµ Arkaplan MÃ¼ziÄŸi Ekle")

        music_options = get_music_options()
        selected_music = st.selectbox(
            "MÃ¼zik TÃ¼rÃ¼ SeÃ§in:",
            list(music_options.keys()),
            format_func=lambda k: music_options[k],
        )

        # Ã–zel mÃ¼zik yÃ¼kleme seÃ§eneÄŸi
        if selected_music == "custom":
            uploaded_music = st.file_uploader(
                "Kendi mÃ¼ziÄŸinizi yÃ¼kleyin:", type=["mp3", "wav", "ogg"]
            )
            if uploaded_music:
                # GeÃ§ici dosya oluÅŸtur
                temp_dir = tempfile.mkdtemp()
                music_path = os.path.join(
                    temp_dir, f"custom_music.{uploaded_music.name.split('.')[-1]}"
                )

                with open(music_path, "wb") as f:
                    f.write(uploaded_music.getbuffer())

                st.session_state["background_music_path"] = music_path
                st.success("MÃ¼zik baÅŸarÄ±yla yÃ¼klendi!")
                st.audio(music_path)

        elif selected_music != "no_music":
            st.info(f"SeÃ§ilen mÃ¼zik: {music_options[selected_music]}")
    def _show_overlay_options(self):
        """Metin ve logo ekleme seÃ§eneklerini gÃ¶ster"""
        st.subheader("âœï¸ Metinler ve Logolar")

        # Metin ekleme seÃ§eneÄŸi
        use_text_overlay = st.checkbox(
            "Videoya Metin Ekle", value=st.session_state.get("use_text_overlay", False)
        )
        st.session_state["use_text_overlay"] = use_text_overlay

        if use_text_overlay:
            text_content = st.text_input(
                "Metin Ä°Ã§eriÄŸi:",
                value=st.session_state.get("overlay_text", ""),
                placeholder="Ã–rn: Emlak360 - www.emlak360.com",
            )
            st.session_state["overlay_text"] = text_content

            text_position = st.selectbox(
                "Metin Konumu:",
                [
                    "bottom",
                    "top",
                    "top-left",
                    "top-right",
                    "bottom-left",
                    "bottom-right",
                ],
                index=0,
                format_func=lambda x: {
                    "bottom": "Alt Orta",
                    "top": "Ãœst Orta",
                    "top-left": "Sol Ãœst",
                    "top-right": "SaÄŸ Ãœst",
                    "bottom-left": "Sol Alt",
                    "bottom-right": "SaÄŸ Alt",
                }.get(x, x),
            )
            st.session_state["overlay_text_position"] = text_position

            text_color = st.color_picker("Metin Rengi:", "#FFFFFF")
            st.session_state["overlay_text_color"] = text_color

        # Logo ekleme seÃ§eneÄŸi
        use_logo_overlay = st.checkbox(
            "Videoya Logo Ekle", value=st.session_state.get("use_logo_overlay", False)
        )
        st.session_state["use_logo_overlay"] = use_logo_overlay

        if use_logo_overlay:
            uploaded_logo = st.file_uploader(
                "Logo YÃ¼kleyin:", type=["png", "jpg", "jpeg"]
            )

            if uploaded_logo:
                # Logo pozisyonu ve boyutu
                logo_img = Image.open(uploaded_logo)
                st.session_state["overlay_logo"] = logo_img

                col1, col2 = st.columns(2)

                with col1:
                    st.image(logo_img, caption="Logo Ã–nizleme", width=200)

                with col2:
                    logo_position = st.selectbox(
                        "Logo Konumu:",
                        ["bottom-right", "bottom-left", "top-right", "top-left"],
                        index=0,
                        format_func=lambda x: {
                            "bottom-right": "SaÄŸ Alt",
                            "bottom-left": "Sol Alt",
                            "top-right": "SaÄŸ Ãœst",
                            "top-left": "Sol Ãœst",
                        }.get(x, x),
                    )
                    st.session_state["overlay_logo_position"] = logo_position

                    logo_size = st.slider("Logo Boyutu (%):", 5, 30, 15)
                    st.session_state["overlay_logo_size"] = logo_size

                    logo_opacity = st.slider(
                        "Logo ÅeffaflÄ±ÄŸÄ±:", 0.1, 1.0, 0.8, step=0.1
                    )
                    st.session_state["overlay_logo_opacity"] = logo_opacity

    def _show_advanced_effects(self):
        """Show advanced video effect options"""
        st.subheader("ğŸ¬ GeliÅŸmiÅŸ Video Efektleri")
        
        # Cinematic color grading options
        st.write("**Renk Efektleri**")
        cinematic_effect = st.selectbox(
            "Sinematik Efekt:",
            ["Yok", "Standart Sinematik", "SÄ±cak Tonlar", "SoÄŸuk Tonlar", "Vintage"],
            format_func=lambda x: {
                "Yok": "Efekt Yok",
                "Standart Sinematik": "Standart Sinematik GÃ¶rÃ¼nÃ¼m",
                "SÄ±cak Tonlar": "SÄ±cak Tonlar (Emlak Ä°Ã§ Mekan)",
                "SoÄŸuk Tonlar": "SoÄŸuk Tonlar (Modern TasarÄ±m)",
                "Vintage": "Vintage/Nostaljik"
            }.get(x, x)
        )
        
        effect_map = {
            "Standart Sinematik": "cinematic",
            "SÄ±cak Tonlar": "warm",
            "SoÄŸuk Tonlar": "cool",
            "Vintage": "vintage"
        }
        
        if cinematic_effect != "Yok":
            st.session_state["cinematic_effect"] = effect_map.get(cinematic_effect)
            st.success(f"'{cinematic_effect}' efekti uygulanacak")
        else:
            st.session_state.pop("cinematic_effect", None)
        
        # Stabilization option
        st.write("**Video Stabilizasyonu**")
        stabilize = st.checkbox("Video stabilizasyonu uygula (kamera titremelerini azaltÄ±r)", value=True)
        st.session_state["stabilize_video"] = stabilize
        
        if stabilize:
            st.info("Stabilizasyon, video oluÅŸturma sÃ¼resini uzatabilir ancak daha profesyonel sonuÃ§lar saÄŸlar.")
        
        # Deep image enhancement
        st.write("**GÃ¶rÃ¼ntÃ¼ Ä°yileÅŸtirme**")
        deep_enhance = st.checkbox("Yapay zeka ile gÃ¶rÃ¼ntÃ¼ kalitesini artÄ±r", value=False)
        st.session_state["deep_enhance"] = deep_enhance
        
        if deep_enhance:
            st.info("Bu Ã¶zellik, gÃ¶rÃ¼ntÃ¼lerin yapay zeka ile iÅŸlenmesini saÄŸlar ve daha keskin, detaylÄ± sonuÃ§lar Ã¼retir.")
            # Add deep enhancement options
            col1, col2 = st.columns(2)
            with col1:
                resolution_boost = st.checkbox("Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k artÄ±rma", value=True)
                st.session_state["deep_enhance_resolution"] = resolution_boost
            with col2:
                denoise = st.checkbox("GÃ¼rÃ¼ltÃ¼ azaltma", value=True)
                st.session_state["deep_enhance_denoise"] = denoise

    def _generate_video(self):
        """Generate video with progress tracking"""
        try:
            # Create progress placeholder
            progress_placeholder = st.empty()
            progress_bar = progress_placeholder.progress(0)
            status_text = st.empty()
            
            with st.spinner("Video oluÅŸturma baÅŸlatÄ±lÄ±yor..."):
                all_images = []
                if "maps_images" in st.session_state:
                    all_images.extend(st.session_state["maps_images"][:8])
                if "user_images" in st.session_state:
                    all_images.extend(st.session_state["user_images"][:5])

                if not all_images:
                    st.error("En az bir gÃ¶rÃ¼ntÃ¼ gerekli!")
                    return

                # Start background task with correct arguments
                task_id = self.task_manager.start_task(
                    generate_video_in_background,
                    task_args=(
                        all_images,
                        st.session_state["audio_path"],
                        st.session_state["transition_type"],
                        st.session_state["fps"],
                        st.session_state["video_quality"]
                    ),
                    task_name="video_generation",
                    timeout=180
                )
                
                st.session_state["video_task_id"] = task_id
                
        except Exception as e:
            st.error(f"Video oluÅŸturma hatasÄ±: {str(e)}")
            st.exception(e)  # Show detailed error traceback in UI
            if "video_task_id" in st.session_state:
                del st.session_state["video_task_id"]


class PropertyVideoWizard:
    """AdÄ±m adÄ±m rehber arayÃ¼zÃ¼ iÃ§in sÄ±nÄ±f"""

    def __init__(self):
        self.step = st.session_state.get("wizard_step", 0)
        self.steps = [
            self.address_step,
            self.property_details_step,
            self.audio_generation_step,
            self.image_collection_step,
            self.video_generation_step,
        ]
        # Task manager ekle
        self.task_manager = BackgroundTaskManager()

    def show(self):
        """Wizard arayÃ¼zÃ¼nÃ¼ gÃ¶ster"""
        # Ä°lerleme Ã§ubuÄŸu
        st.progress(self.step / (len(self.steps) - 1))

        # Mevcut adÄ±mÄ± gÃ¶ster
        self.steps[self.step]()

        # Gezinme kontrolleri
        col1, col2 = st.columns(2)
        with col1:
            if self.step > 0:
                if st.button("â¬…ï¸ Ã–nceki AdÄ±m"):
                    st.session_state["wizard_step"] = self.step - 1
                    safe_rerun()
        with col2:
            if self.step < len(self.steps) - 1:
                if st.button("Sonraki AdÄ±m â¡ï¸"):
                    # Ä°lerlemeden Ã¶nce mevcut adÄ±mÄ± doÄŸrula
                    if self.validate_step():
                        st.session_state["wizard_step"] = self.step + 1
                        safe_rerun()

    def validate_step(self):
        """Mevcut adÄ±mÄ±n geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol et"""
        # Her adÄ±m iÃ§in doÄŸrulama mantÄ±ÄŸÄ± burada uygulanabilir
        if self.step == 0 and "property_location" not in st.session_state:
            st.error("Devam etmek iÃ§in bir adres girin!")
            return False
        elif self.step == 1 and "property_text" not in st.session_state:
            st.error("Devam etmek iÃ§in emlak metnini oluÅŸturun!")
            return False
        elif self.step == 2 and "audio_path" not in st.session_state:
            st.error("Devam etmek iÃ§in sesli anlatÄ±m oluÅŸturun!")
            return False
        elif self.step == 3 and not (
            "maps_images" in st.session_state or "user_images" in st.session_state
        ):
            st.error("Devam etmek iÃ§in en az bir gÃ¶rÃ¼ntÃ¼ ekleyin!")
            return False

        return True

    # AdÄ±m uygulamalarÄ± (her biri ilgili controller'Ä± kullanÄ±r)
    def address_step(self):
        st.header("1. AdÄ±m: Emlak Konumunu Belirleyin")
        # PropertyController kullanÄ±labilir burada...

    def property_details_step(self):
        st.header("2. AdÄ±m: Emlak Bilgilerini Girin")
        property_controller = PropertyController()
        property_controller.show_property_form()

    def audio_generation_step(self):
        st.header("3. AdÄ±m: Sesli AnlatÄ±m OluÅŸturun")
        audio_controller = AudioController()
        audio_controller.show_audio_generation()

    def image_collection_step(self):
        st.header("4. AdÄ±m: GÃ¶rÃ¼ntÃ¼leri ToplayÄ±n")
        image_controller = ImageController()
        image_controller.show_image_collection()

    def video_generation_step(self):
        st.header("5. AdÄ±m: Video OluÅŸturun")
        video_controller = VideoController(self.task_manager)
        video_controller.show_video_generation()


# Ana uygulama Ã§alÄ±ÅŸtÄ±rma kodu
if __name__ == "__main__":
    app = EmlakVideoApp()
    app.run()
-e 

